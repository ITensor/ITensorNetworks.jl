<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · ITensorNetworks.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://mtfishman.github.io/ITensorNetworks.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>ITensorNetworks.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ITensorNetworks"><a class="docs-heading-anchor" href="#ITensorNetworks">ITensorNetworks</a><a id="ITensorNetworks-1"></a><a class="docs-heading-anchor-permalink" href="#ITensorNetworks" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/mtfishman/ITensorNetworks.jl">ITensorNetworks</a>.</p><ul><li><a href="#ITensorNetworks.CURRENT_PARTITIONING_BACKEND"><code>ITensorNetworks.CURRENT_PARTITIONING_BACKEND</code></a></li><li><a href="#ITensorNetworks.Backend"><code>ITensorNetworks.Backend</code></a></li><li><a href="#ITensorNetworks.ITensorNetwork"><code>ITensorNetworks.ITensorNetwork</code></a></li><li><a href="#ITensorNetworks.ProjMPOApply"><code>ITensorNetworks.ProjMPOApply</code></a></li><li><a href="#ITensorNetworks.ProjMPS2"><code>ITensorNetworks.ProjMPS2</code></a></li><li><a href="#ITensorNetworks.ProjTTN"><code>ITensorNetworks.ProjTTN</code></a></li><li><a href="#ITensorNetworks.ProjTTNSum"><code>ITensorNetworks.ProjTTNSum</code></a></li><li><a href="#ITensorNetworks.SweepStep"><code>ITensorNetworks.SweepStep</code></a></li><li><a href="#ITensorNetworks.TDVPInfo"><code>ITensorNetworks.TDVPInfo</code></a></li><li><a href="#ITensorNetworks.TTN-Union{Tuple{V}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, IndsNetwork{V, &lt;:ITensors.Index}}} where V"><code>ITensorNetworks.TTN</code></a></li><li><a href="#ITensorNetworks.TreeTensorNetwork"><code>ITensorNetworks.TreeTensorNetwork</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:sa_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:greedy}, Vector{ITensors.ITensor}}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:tree_sa}, Any}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:kahypar_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.current_partitioning_backend-Tuple{}"><code>ITensorNetworks.current_partitioning_backend</code></a></li><li><a href="#ITensorNetworks.delta_network-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.delta_network</code></a></li><li><a href="#ITensorNetworks.find_subgraph-Tuple{Any, DataGraph}"><code>ITensorNetworks.find_subgraph</code></a></li><li><a href="#ITensorNetworks.findall_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_edges</code></a></li><li><a href="#ITensorNetworks.findall_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_vertices</code></a></li><li><a href="#ITensorNetworks.findfirst_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_edges</code></a></li><li><a href="#ITensorNetworks.findfirst_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_vertices</code></a></li><li><a href="#ITensorNetworks.finite_state_machine-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.finite_state_machine</code></a></li><li><a href="#ITensorNetworks.fsmTTN-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.fsmTTN</code></a></li><li><a href="#ITensorNetworks.get_single_site_expec-Tuple{ITensorNetwork, DataGraph, ITensorNetwork, Any}"><code>ITensorNetworks.get_single_site_expec</code></a></li><li><a href="#ITensorNetworks.get_two_site_expec-Tuple{ITensorNetwork, DataGraph, ITensorNetwork, Any, Any}"><code>ITensorNetworks.get_two_site_expec</code></a></li><li><a href="#ITensorNetworks.heisenberg-Tuple{Integer}"><code>ITensorNetworks.heisenberg</code></a></li><li><a href="#ITensorNetworks.heisenberg-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.heisenberg</code></a></li><li><a href="#ITensorNetworks.ising-Tuple{Integer}"><code>ITensorNetworks.ising</code></a></li><li><a href="#ITensorNetworks.ising-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.ising</code></a></li><li><a href="#ITensorNetworks.ising_network-Tuple{Type, IndsNetwork, Number}"><code>ITensorNetworks.ising_network</code></a></li><li><a href="#ITensorNetworks.ising_network-Tuple{Type, NamedGraphs.NamedGraph, Number}"><code>ITensorNetworks.ising_network</code></a></li><li><a href="#ITensorNetworks.iterate_single_site_expec-Tuple{ITensorNetwork, DataGraph, Int64, ITensorNetwork, Any}"><code>ITensorNetworks.iterate_single_site_expec</code></a></li><li><a href="#ITensorNetworks.iterate_two_site_expec-Tuple{ITensorNetwork, DataGraph, Int64, ITensorNetwork, Any, Any}"><code>ITensorNetworks.iterate_two_site_expec</code></a></li><li><a href="#ITensorNetworks.partition-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition</code></a></li><li><a href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition_vertices</code></a></li><li><a href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.partition_vertices</code></a></li><li><a href="#ITensorNetworks.randomITensorNetwork-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.randomITensorNetwork</code></a></li><li><a href="#ITensorNetworks.relabel_sites-Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, Dictionaries.AbstractDictionary}"><code>ITensorNetworks.relabel_sites</code></a></li><li><a href="#ITensorNetworks.set_partitioning_backend!-Tuple{Union{Missing, String, ITensorNetworks.Backend}}"><code>ITensorNetworks.set_partitioning_backend!</code></a></li><li><a href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.subgraphs</code></a></li><li><a href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.subgraphs</code></a></li><li><a href="#ITensorNetworks.svdTTN-Union{Tuple{VT}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{VT, &lt;:ITensors.Index}, VT}} where {C, VT}"><code>ITensorNetworks.svdTTN</code></a></li><li><a href="#ITensorNetworks.tdvp-Tuple{Any, Vector{&lt;:Union{ITensors.MPO, TreeTensorNetwork}}, Number, Union{ITensors.MPS, TreeTensorNetwork}}"><code>ITensorNetworks.tdvp</code></a></li><li><a href="#ITensorNetworks.tdvp-Tuple{Any, Union{ITensors.MPO, TreeTensorNetwork}, Number, Union{ITensors.MPS, TreeTensorNetwork}}"><code>ITensorNetworks.tdvp</code></a></li><li><a href="#ITensorNetworks.to_vec-Tuple{Any}"><code>ITensorNetworks.to_vec</code></a></li><li><a href="#ITensorNetworks.two_site_rdm_bp-Tuple{ITensorNetwork, ITensorNetwork, DataGraph, Any, Any, IndsNetwork, DataGraph}"><code>ITensorNetworks.two_site_rdm_bp</code></a></li><li><a href="#ITensorNetworks.update_all_mts-Tuple{ITensorNetwork, DataGraph}"><code>ITensorNetworks.update_all_mts</code></a></li><li><a href="#ITensorNetworks.update_mt-Tuple{ITensorNetwork, Vector, Vector{ITensors.ITensor}}"><code>ITensorNetworks.update_mt</code></a></li><li><a href="#KrylovKit.linsolve"><code>KrylovKit.linsolve</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.CURRENT_PARTITIONING_BACKEND" href="#ITensorNetworks.CURRENT_PARTITIONING_BACKEND"><code>ITensorNetworks.CURRENT_PARTITIONING_BACKEND</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Current default graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L14-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.Backend" href="#ITensorNetworks.Backend"><code>ITensorNetworks.Backend</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ITensorNetwork" href="#ITensorNetworks.ITensorNetwork"><code>ITensorNetworks.ITensorNetwork</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ITensorNetwork</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/itensornetwork.jl#L3-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ProjMPOApply" href="#ITensorNetworks.ProjMPOApply"><code>ITensorNetworks.ProjMPOApply</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A ProjMPOApply represents the application of an MPO <code>H</code> onto an MPS <code>psi0</code> but &quot;projected&quot; by the basis of a different MPS <code>psi</code> (which could be an approximation to H|psi&gt;).</p><p>As an implementation of the AbstractProjMPO type, it supports multiple <code>nsite</code> values for one- and two-site algorithms.</p><pre><code class="nohighlight hljs">     *--*--*-      -*--*--*--*--*--* &lt;psi|
     |  |  |  |  |  |  |  |  |  |  |
     h--h--h--h--h--h--h--h--h--h--h H  
     |  |  |  |  |  |  |  |  |  |  |
     o--o--o-      -o--o--o--o--o--o |psi0&gt;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/projmpo_apply.jl#L4-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ProjMPS2" href="#ITensorNetworks.ProjMPS2"><code>ITensorNetworks.ProjMPS2</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Holds the following data where psi is the MPS being optimized and M is the  MPS held constant by the ProjMPS.</p><pre><code class="nohighlight hljs">     o--o--o--o--o--o--o--o--o--o--o &lt;M|
     |  |  |  |  |  |  |  |  |  |  |
     *--*--*-      -*--*--*--*--*--* |psi&gt;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/projmps2.jl#L5-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ProjTTN" href="#ITensorNetworks.ProjTTN"><code>ITensorNetworks.ProjTTN</code></a> — <span class="docstring-category">Type</span></header><section><div><p>ProjTTN</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/projttns/projttn.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ProjTTNSum" href="#ITensorNetworks.ProjTTNSum"><code>ITensorNetworks.ProjTTNSum</code></a> — <span class="docstring-category">Type</span></header><section><div><p>ProjTTNSum</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/projttns/projttnsum.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.SweepStep" href="#ITensorNetworks.SweepStep"><code>ITensorNetworks.SweepStep</code></a> — <span class="docstring-category">Type</span></header><section><div><p>struct SweepStep{V}</p><p>Auxiliary object specifying a single local update step in a tree sweeping algorithm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/tree_sweeping.jl#L5-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.TDVPInfo" href="#ITensorNetworks.TDVPInfo"><code>ITensorNetworks.TDVPInfo</code></a> — <span class="docstring-category">Type</span></header><section><div><p>#fields</p><ul><li><code>maxtruncerr::Float64</code>: the maximum tuncation error</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/tdvpinfo.jl#L1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.TTN-Union{Tuple{V}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, IndsNetwork{V, &lt;:ITensors.Index}}} where V" href="#ITensorNetworks.TTN-Union{Tuple{V}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, IndsNetwork{V, &lt;:ITensors.Index}}} where V"><code>ITensorNetworks.TTN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">TTN(os::OpSum, sites::IndsNetwork{&lt;:Index}; kwargs...)
TTN(eltype::Type{&lt;:Number}, os::OpSum, sites::IndsNetwork{&lt;:Index}; kwargs...)</code></pre><p>Convert an OpSum object <code>os</code> to a TreeTensorNetwork, with indices given by <code>sites</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/opsum_to_ttn.jl#L513-L518">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.TreeTensorNetwork" href="#ITensorNetworks.TreeTensorNetwork"><code>ITensorNetworks.TreeTensorNetwork</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TreeTensorNetwork{V} &lt;: AbstractTreeTensorNetwork{V}</code></pre><p><strong>Fields</strong></p><ul><li>itensor_network::ITensorNetwork{V}</li><li>ortho_lims::Vector{V}: A vector of vertices defining the orthogonality limits.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/ttn.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:greedy}, Vector{ITensors.ITensor}}" href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:greedy}, Vector{ITensors.ITensor}}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GreedyMethod(; method=MinSpaceOut(), nrepeat=10)</code></pre><p>The fast but poor greedy optimizer. Input arguments are:</p><ul><li><code>method</code> is <code>MinSpaceDiff()</code> or <code>MinSpaceOut</code>.<ul><li><code>MinSpaceOut</code> choose one of the contraction that produces a minimum output tensor size,</li><li><code>MinSpaceDiff</code> choose one of the contraction that decrease the space most.</li></ul></li><li><code>nrepeat</code> is the number of repeatition, returns the best contraction order.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/contraction_sequences.jl#L19-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:kahypar_bipartite}, Any}" href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:kahypar_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">KaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),
                   max_group_size=40, greedy_config=GreedyMethod())</code></pre><p>Optimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are:</p><ul><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>imbalances</code> is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>greedy_config</code> is a greedy optimizer.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li><li><a href="https://arxiv.org/abs/2103.03074">Simulating the Sycamore quantum supremacy circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/contraction_sequences.jl#L94-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:sa_bipartite}, Any}" href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:sa_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">SABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000
              max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)</code></pre><p>Optimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are:</p><ul><li><code>size_dict</code>, a dictionary that specifies leg dimensions,</li><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>βs</code> is a list of inverse temperature <code>1/T</code>,</li><li><code>niters</code> is the number of iteration in each temperature,</li><li><code>ntrials</code> is the number of repetition (with different random seeds),</li><li><code>greedy_config</code> configures the greedy method,</li><li><code>initializer</code>, the partition configuration initializer, one can choose <code>:random</code> or <code>:greedy</code> (slow but better).</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/contraction_sequences.jl#L64-L84">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:tree_sa}, Any}" href="#ITensorNetworks.contraction_sequence-Tuple{ITensors.Algorithm{:tree_sa}, Any}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">TreeSA(; sc_target=20, βs=collect(0.01:0.05:15), ntrials=10, niters=50,
         sc_weight=1.0, rw_weight=0.2, initializer=:greedy, greedy_config=GreedyMethod(; nrepeat=1))</code></pre><p>Optimize the einsum contraction pattern using the simulated annealing on tensor expression tree.</p><ul><li><code>sc_target</code> is the target space complexity,</li><li><code>ntrials</code>, <code>βs</code> and <code>niters</code> are annealing parameters, doing <code>ntrials</code> indepedent annealings, each has inverse tempteratures specified by <code>βs</code>, in each temperature, do <code>niters</code> updates of the tree.</li><li><code>sc_weight</code> is the relative importance factor of space complexity in the loss compared with the time complexity.</li><li><code>rw_weight</code> is the relative importance factor of memory read and write in the loss compared with the time complexity.</li><li><code>initializer</code> specifies how to determine the initial configuration, it can be <code>:greedy</code> or <code>:random</code>. If it is using <code>:greedy</code> method to generate the initial configuration, it also uses two extra arguments <code>greedy_method</code> and <code>greedy_nrepeat</code>.</li><li><code>nslices</code> is the number of sliced legs, default is 0.</li><li><code>fixed_slices</code> is a vector of sliced legs, default is <code>[]</code>.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2108.05665">Recursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/contraction_sequences.jl#L38-L54">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.current_partitioning_backend-Tuple{}" href="#ITensorNetworks.current_partitioning_backend-Tuple{}"><code>ITensorNetworks.current_partitioning_backend</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Get the graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.delta_network-Tuple{Type, IndsNetwork}" href="#ITensorNetworks.delta_network-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.delta_network</code></a> — <span class="docstring-category">Method</span></header><section><div><p>RETURN A TENSOR NETWORK WITH COPY TENSORS ON EACH VERTEX.  Note that passing a link_space will mean the indices of the resulting network don&#39;t match those of the input indsnetwork</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/specialitensornetworks.jl#L1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.find_subgraph-Tuple{Any, DataGraph}" href="#ITensorNetworks.find_subgraph-Tuple{Any, DataGraph}"><code>ITensorNetworks.find_subgraph</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the subgraph which contains the specified vertex.</p><p>TODO: Rename something more general, like:</p><p>findfirst<em>in</em>vertex_data(item, graph::AbstractDataGraph)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L186-L192">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findall_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findall_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_edges</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find all edges <code>e</code> such that <code>f(graph[e]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L172-L174">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findall_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findall_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find all vertices <code>v</code> such that <code>f(graph[v]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L158-L160">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findfirst_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findfirst_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_edges</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the edge <code>e</code> such that <code>f(graph[e]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L179-L181">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findfirst_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findfirst_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the vertex <code>v</code> such that <code>f(graph[v]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L165-L167">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.finite_state_machine-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}" href="#ITensorNetworks.finite_state_machine-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.finite_state_machine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">finite_state_machine(os::OpSum{C}, sites::IndsNetwork{V,&lt;:Index}, root_vertex::V) where {C,V}</code></pre><p>Finite state machine generator for ITensors.OpSum Hamiltonian defined on a tree graph. The site Index graph must be a tree graph, and the chosen root  must be a leaf vertex of this tree. Returns a DataGraph of SparseArrayKit.SparseArrays</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/opsum_to_ttn.jl#L46-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.fsmTTN-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}" href="#ITensorNetworks.fsmTTN-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.fsmTTN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fsmTTN(os::OpSum{C}, sites::IndsNetwork{V,&lt;:Index}, root_vertex::V, kwargs...) where {C,V}</code></pre><p>Construct a dense TreeTensorNetwork from sparse finite state machine represenatation, without compression.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/opsum_to_ttn.jl#L177-L182">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.get_single_site_expec-Tuple{ITensorNetwork, DataGraph, ITensorNetwork, Any}" href="#ITensorNetworks.get_single_site_expec-Tuple{ITensorNetwork, DataGraph, ITensorNetwork, Any}"><code>ITensorNetworks.get_single_site_expec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>given two flat networks psi and psi0, calculate the ratio of their contraction centred on the the subgraph containing v. The message tensors should be formulated over psi Link indices between psi and psi0 should be consistent so the mts can be applied to both</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/beliefpropagation.jl#L101-L104">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.get_two_site_expec-Tuple{ITensorNetwork, DataGraph, ITensorNetwork, Any, Any}" href="#ITensorNetworks.get_two_site_expec-Tuple{ITensorNetwork, DataGraph, ITensorNetwork, Any, Any}"><code>ITensorNetworks.get_two_site_expec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>given two flat networks psi and psi0, calculate the ratio of their contraction centred on the subgraph(s) containing v1 and v2. The message tensors should be formulated over psi.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/beliefpropagation.jl#L133-L135">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.heisenberg-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.heisenberg-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.heisenberg</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Random field J1-J2 Heisenberg model on a general graph</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/models.jl#L4-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.heisenberg-Tuple{Integer}" href="#ITensorNetworks.heisenberg-Tuple{Integer}"><code>ITensorNetworks.heisenberg</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Random field J1-J2 Heisenberg model on a chain of length N</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/models.jl#L70-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.ising-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.ising</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Next-to-nearest-neighbor Ising model (ZZX) on a general graph</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/models.jl#L40-L42">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising-Tuple{Integer}" href="#ITensorNetworks.ising-Tuple{Integer}"><code>ITensorNetworks.ising</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Next-to-nearest-neighbor Ising model (ZZX) on a chain of length N</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/models.jl#L75-L77">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising_network-Tuple{Type, IndsNetwork, Number}" href="#ITensorNetworks.ising_network-Tuple{Type, IndsNetwork, Number}"><code>ITensorNetworks.ising_network</code></a> — <span class="docstring-category">Method</span></header><section><div><p>BUILD Z OF CLASSICAL ISING MODEL ON A GIVEN GRAPH AT INVERSE TEMP BETA H = -\sum<em>{(v,v&#39;) \in edges}\sigma^{z}</em>{v}\sigma^{z}_{v&#39;} TAKE AS AN OPTIONAL ARGUMENT A LIST OF VERTICES OVER WHICH TO APPLY A SZ. THE RESULTANT NETWORK CAN THEN BE CONTRACTED AND DIVIDED BY THE ACTUAL PARTITION FUNCTION TO GET THAT OBSERVABLE INDSNETWORK IS ASSUMED TO BE BUILT FROM A GRAPH (NO SITE INDS) AND OF LINK SPACE 2</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/specialitensornetworks.jl#L21-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising_network-Tuple{Type, NamedGraphs.NamedGraph, Number}" href="#ITensorNetworks.ising_network-Tuple{Type, NamedGraphs.NamedGraph, Number}"><code>ITensorNetworks.ising_network</code></a> — <span class="docstring-category">Method</span></header><section><div><p>BUILD Z OF CLASSICAL ISING MODEL ON A GIVEN GRAPH AT INVERSE TEMP BETA H = -\sum<em>{(v,v&#39;) \in edges}\sigma^{z}</em>{v}\sigma^{z}_{v&#39;} TAKE AS AN OPTIONAL ARGUMENT A LIST OF VERTICES OVER WHICH TO APPLY A SZ. THE RESULTANT NETWORK CAN THEN BE CONTRACTED AND DIVIDED BY THE ACTUAL PARTITION FUNCTION TO GET THAT OBSERVABLE</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/specialitensornetworks.jl#L56-L60">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.iterate_single_site_expec-Tuple{ITensorNetwork, DataGraph, Int64, ITensorNetwork, Any}" href="#ITensorNetworks.iterate_single_site_expec-Tuple{ITensorNetwork, DataGraph, Int64, ITensorNetwork, Any}"><code>ITensorNetworks.iterate_single_site_expec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Starting with initial guess for messagetensors, monitor the convergence of an observable on a single site v (which is emedded in tnO)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/beliefpropagation.jl#L213-L215">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.iterate_two_site_expec-Tuple{ITensorNetwork, DataGraph, Int64, ITensorNetwork, Any, Any}" href="#ITensorNetworks.iterate_two_site_expec-Tuple{ITensorNetwork, DataGraph, Int64, ITensorNetwork, Any, Any}"><code>ITensorNetworks.iterate_two_site_expec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Starting with initial guess for messagetensors, monitor the convergence of an observable on a pair of sites v1 and v2 (which is emedded in tnO)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/beliefpropagation.jl#L240-L242">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.partition-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.partition-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition(g::AbstractGraph; npartitions::Integer, kwargs...)
partition(g::AbstractGraph, subgraph_vertices)</code></pre><p>Given a graph <code>g</code>, partition <code>g</code> into <code>npartitions</code> partitions or into partitions with <code>nvertices_per_partition</code> vertices per partition. The partitioning tries to keep all subgraphs the same size and minimize edges cut between them.</p><p>Alternatively, specify a desired partitioning with a collection of sugraph vertices.</p><p>Returns a data graph where each vertex contains the corresponding subgraph as vertex data. The edges indicates which subgraphs are connected, and the edge data stores a dictionary with two fields. The field <code>:edges</code> stores a list of the edges of the original graph that were connecting the two subgraphs, and <code>:edge_data</code> stores a dictionary mapping edges of the original graph to the data living on the edges of the original graph, if it existed.</p><p>Therefore, one should be able to extract that data and recreate the original graph from the results of <code>partition</code>.</p><p>A graph partitioning backend such as Metis or KaHyPar needs to be installed for this function to work if the subgraph vertices aren&#39;t specified explicitly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L254-L278">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.partition_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition_vertices(g::AbstractGraph, subgraph_vertices::Vector)</code></pre><p>Given a graph (<code>g</code>) and groups of vertices defining subgraphs of that graph (<code>subgraph_vertices</code>), return a DataGraph storing the subgraph vertices on the vertices of the graph and with edges denoting which subgraphs of the original graph have edges connecting them, along with edge data storing the original edges that were connecting the subgraphs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L110-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition_vertices(g::AbstractGraph; npartitions, nvertices_per_partition, kwargs...)</code></pre><p>Given a graph <code>g</code>, partition the vertices of <code>g</code> into &#39;npartitions&#39; partitions or into partitions with <code>nvertices_per_partition</code> vertices per partition. Try to keep all subgraphs the same size and minimise edges cut between them Returns a datagraph where each vertex contains the list of vertices involved in that subgraph. The edges state which subgraphs are connected. A graph partitioning backend such as Metis or KaHyPar needs to be installed for this function to work.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L141-L149">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.randomITensorNetwork-Tuple{Type, IndsNetwork}" href="#ITensorNetworks.randomITensorNetwork-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.randomITensorNetwork</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build an ITensor network on a graph specified by the inds network s. Bond<em>dim is given by link</em>space and entries are randomised (normal distribution, mean 0 std 1)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/specialitensornetworks.jl#L69-L71">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.relabel_sites-Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, Dictionaries.AbstractDictionary}" href="#ITensorNetworks.relabel_sites-Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, Dictionaries.AbstractDictionary}"><code>ITensorNetworks.relabel_sites</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Relabel sites in OpSum according to given site map</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/utility.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.set_partitioning_backend!-Tuple{Union{Missing, String, ITensorNetworks.Backend}}" href="#ITensorNetworks.set_partitioning_backend!-Tuple{Union{Missing, String, ITensorNetworks.Backend}}"><code>ITensorNetworks.set_partitioning_backend!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Set the graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L24-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.subgraphs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">subgraphs(g::AbstractGraph, subgraph_vertices)</code></pre><p>Return a collection of subgraphs of <code>g</code> defined by the subgraph vertices <code>subgraph_vertices</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L201-L206">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.subgraphs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">subgraphs(g::AbstractGraph; npartitions::Integer, kwargs...)</code></pre><p>Given a graph <code>g</code>, partition <code>g</code> into <code>npartitions</code> partitions or into partitions with <code>nvertices_per_partition</code> vertices per partition, returning a list of subgraphs. Try to keep all subgraphs the same size and minimise edges cut between them. A graph partitioning backend such as Metis or KaHyPar needs to be installed for this function to work.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/partition.jl#L211-L219">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.svdTTN-Union{Tuple{VT}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{VT, &lt;:ITensors.Index}, VT}} where {C, VT}" href="#ITensorNetworks.svdTTN-Union{Tuple{VT}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{VT, &lt;:ITensors.Index}, VT}} where {C, VT}"><code>ITensorNetworks.svdTTN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">svdTTN(os::OpSum{C}, sites::IndsNetwork{V&lt;:Index}, root_vertex::V, kwargs...) where {C,V}</code></pre><p>Construct a dense TreeTensorNetwork from a symbolic OpSum representation of a Hamiltonian, compressing shared interaction channels.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/opsum_to_ttn.jl#L217-L222">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.tdvp-Tuple{Any, Union{ITensors.MPO, TreeTensorNetwork}, Number, Union{ITensors.MPS, TreeTensorNetwork}}" href="#ITensorNetworks.tdvp-Tuple{Any, Union{ITensors.MPO, TreeTensorNetwork}, Number, Union{ITensors.MPS, TreeTensorNetwork}}"><code>ITensorNetworks.tdvp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tdvp(H::MPS,psi0::MPO,t::Number; kwargs...)
tdvp(H::TTN,psi0::TTN,t::Number; kwargs...)</code></pre><p>Use the time dependent variational principle (TDVP) algorithm to compute <code>exp(t*H)*psi0</code> using an efficient algorithm based on alternating optimization of the state tensors and local Krylov exponentiation of H.</p><p>Returns:</p><ul><li><code>psi</code> - time-evolved state</li></ul><p>Optional keyword arguments:</p><ul><li><code>outputlevel::Int = 1</code> - larger outputlevel values resulting in printing more information and 0 means no output</li><li><code>observer</code> - object implementing the <a href="@ref observer">Observer</a> interface which can perform measurements and stop early</li><li><code>write_when_maxdim_exceeds::Int</code> - when the allowed maxdim exceeds this value, begin saving tensors to disk to free memory in large calculations</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/tdvp_generic.jl#L126-L142">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.tdvp-Tuple{Any, Vector{&lt;:Union{ITensors.MPO, TreeTensorNetwork}}, Number, Union{ITensors.MPS, TreeTensorNetwork}}" href="#ITensorNetworks.tdvp-Tuple{Any, Vector{&lt;:Union{ITensors.MPO, TreeTensorNetwork}}, Number, Union{ITensors.MPS, TreeTensorNetwork}}"><code>ITensorNetworks.tdvp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tdvp(Hs::Vector{MPO},psi0::MPS,t::Number; kwargs...)
tdvp(Hs::Vector{MPO},psi0::MPS,t::Number, sweeps::Sweeps; kwargs...)</code></pre><p>Use the time dependent variational principle (TDVP) algorithm to compute <code>exp(t*H)*psi0</code> using an efficient algorithm based on alternating optimization of the MPS tensors and local Krylov exponentiation of H.</p><p>This version of <code>tdvp</code> accepts a representation of H as a Vector of MPOs, Hs = [H1,H2,H3,...] such that H is defined as H = H1+H2+H3+... Note that this sum of MPOs is not actually computed; rather the set of MPOs [H1,H2,H3,..] is efficiently looped over at  each step of the algorithm when optimizing the MPS.</p><p>Returns:</p><ul><li><code>psi::MPS</code> - time-evolved MPS</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/tdvp_generic.jl#L161-L179">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.to_vec-Tuple{Any}" href="#ITensorNetworks.to_vec-Tuple{Any}"><code>ITensorNetworks.to_vec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">to_vec(x)</code></pre><p>Transform <code>x</code> into a <code>Vector</code>, and return the vector, and a closure which inverts the transformation.</p><p>Modeled after FiniteDifferences.to_vec:</p><p>https://github.com/JuliaDiff/FiniteDifferences.jl/blob/main/src/to_vec.jl</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/solver_utils.jl#L5-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.two_site_rdm_bp-Tuple{ITensorNetwork, ITensorNetwork, DataGraph, Any, Any, IndsNetwork, DataGraph}" href="#ITensorNetworks.two_site_rdm_bp-Tuple{ITensorNetwork, ITensorNetwork, DataGraph, Any, Any, IndsNetwork, DataGraph}"><code>ITensorNetworks.two_site_rdm_bp</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Get two<em>site</em>rdm using belief propagation messagetensors</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/beliefpropagation.jl#L271-L273">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.update_all_mts-Tuple{ITensorNetwork, DataGraph}" href="#ITensorNetworks.update_all_mts-Tuple{ITensorNetwork, DataGraph}"><code>ITensorNetworks.update_all_mts</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Do an update of all message tensors for a given flat ITensornetwork and its partition into sub graphs</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/beliefpropagation.jl#L66-L68">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.update_mt-Tuple{ITensorNetwork, Vector, Vector{ITensors.ITensor}}" href="#ITensorNetworks.update_mt-Tuple{ITensorNetwork, Vector, Vector{ITensors.ITensor}}"><code>ITensorNetworks.update_mt</code></a> — <span class="docstring-category">Method</span></header><section><div><p>DO a single update of a message tensor using the current subgraph and the incoming mts</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/beliefpropagation.jl#L42-L44">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KrylovKit.linsolve" href="#KrylovKit.linsolve"><code>KrylovKit.linsolve</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">linsolve(
    A::ITensors.MPO,
    b::ITensors.MPS,
    x₀::ITensors.MPS
) -&gt; ITensors.MPS
linsolve(
    A::ITensors.MPO,
    b::ITensors.MPS,
    x₀::ITensors.MPS,
    a₀::Number
) -&gt; ITensors.MPS
linsolve(
    A::ITensors.MPO,
    b::ITensors.MPS,
    x₀::ITensors.MPS,
    a₀::Number,
    a₁::Number;
    kwargs...
) -&gt; ITensors.MPS
</code></pre><p>Compute a solution x to the linear system:</p><p>(a₀ + a₁ * A)*x = b</p><p>using starting guess x₀. Leaving a₀, a₁ set to their default values solves the  system A*x = b.</p><p>To adjust the balance between accuracy of solution and speed of the algorithm, it is recommed to first try adjusting the <code>solver_tol</code> keyword argument descibed below.</p><p>Keyword arguments:</p><ul><li><code>ishermitian::Bool=false</code> - should set to true if the MPO A is Hermitian</li><li><code>solver_krylovdim::Int=30</code> - max number of Krylov vectors to build on each solver iteration</li><li><code>solver_maxiter::Int=100</code> - max number outer iterations (restarts) to do in the solver step</li><li><code>solver_tol::Float64=1E-14</code> - tolerance or error goal of the solver</li></ul><p>Overload of <code>KrylovKit.linsolve</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/2391ee445f5c8a7bfbcb8bbb4782bad149ebf3e0/src/treetensornetworks/solvers/linsolve.jl#L2">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Thursday 12 January 2023 20:37">Thursday 12 January 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
