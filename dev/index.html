<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · ITensorNetworks.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://mtfishman.github.io/ITensorNetworks.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>ITensorNetworks.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ITensorNetworks"><a class="docs-heading-anchor" href="#ITensorNetworks">ITensorNetworks</a><a id="ITensorNetworks-1"></a><a class="docs-heading-anchor-permalink" href="#ITensorNetworks" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/mtfishman/ITensorNetworks.jl">ITensorNetworks</a>.</p><ul><li><a href="#ITensorNetworks.CURRENT_PARTITIONING_BACKEND"><code>ITensorNetworks.CURRENT_PARTITIONING_BACKEND</code></a></li><li><a href="#ITensorNetworks.Backend"><code>ITensorNetworks.Backend</code></a></li><li><a href="#ITensorNetworks.ITensorNetwork"><code>ITensorNetworks.ITensorNetwork</code></a></li><li><a href="#ITensorNetworks.ProjTTN"><code>ITensorNetworks.ProjTTN</code></a></li><li><a href="#ITensorNetworks.ProjTTNSum"><code>ITensorNetworks.ProjTTNSum</code></a></li><li><a href="#ITensorNetworks.SweepStep"><code>ITensorNetworks.SweepStep</code></a></li><li><a href="#ITensorNetworks.TDVPInfo"><code>ITensorNetworks.TDVPInfo</code></a></li><li><a href="#ITensorNetworks.TTN-Union{Tuple{V}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, IndsNetwork{V, &lt;:ITensors.Index}}} where V"><code>ITensorNetworks.TTN</code></a></li><li><a href="#ITensorNetworks.TreeTensorNetwork"><code>ITensorNetworks.TreeTensorNetwork</code></a></li><li><a href="#ITensorNetworks._DensityMartrixAlgGraph"><code>ITensorNetworks._DensityMartrixAlgGraph</code></a></li><li><a href="#ITensorNetworks._DensityMatrixAlgCaches"><code>ITensorNetworks._DensityMatrixAlgCaches</code></a></li><li><a href="#ITensorNetworks._approx_binary_tree_itensornetwork!-Tuple{DataGraph, NamedGraphs.NamedGraph}"><code>ITensorNetworks._approx_binary_tree_itensornetwork!</code></a></li><li><a href="#ITensorNetworks._binary_tree_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._binary_tree_structure</code></a></li><li><a href="#ITensorNetworks._contract_deltas-Tuple{ITensorNetwork}"><code>ITensorNetworks._contract_deltas</code></a></li><li><a href="#ITensorNetworks._contract_deltas_ignore_leaf_partitions-Tuple{DataGraph}"><code>ITensorNetworks._contract_deltas_ignore_leaf_partitions</code></a></li><li><a href="#ITensorNetworks._delta_inds_disjointsets-Tuple{Vector{&lt;:ITensors.ITensor}, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._delta_inds_disjointsets</code></a></li><li><a href="#ITensorNetworks._densitymatrix_outinds_to_sim-Tuple{Any, Any}"><code>ITensorNetworks._densitymatrix_outinds_to_sim</code></a></li><li><a href="#ITensorNetworks._distance-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._distance</code></a></li><li><a href="#ITensorNetworks._introot_union!-Tuple{DataStructures.IntDisjointSets, Any, Any}"><code>ITensorNetworks._introot_union!</code></a></li><li><a href="#ITensorNetworks._maxweightoutinds_tn-Tuple{ITensorNetwork, Union{Nothing, Vector{&lt;:ITensors.Index}}}"><code>ITensorNetworks._maxweightoutinds_tn</code></a></li><li><a href="#ITensorNetworks._mincut-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._mincut</code></a></li><li><a href="#ITensorNetworks._mincut_inds-Tuple{Pair{&lt;:ITensorNetwork, &lt;:ITensorNetwork}, Dict{ITensors.Index, ITensors.Index}, Vector{&lt;:Vector{&lt;:ITensors.Index}}}"><code>ITensorNetworks._mincut_inds</code></a></li><li><a href="#ITensorNetworks._mincut_partitions-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._mincut_partitions</code></a></li><li><a href="#ITensorNetworks._mps_partition_inds_order-Tuple{ITensorNetwork, Union{Nothing, Vector{&lt;:ITensors.Index}}}"><code>ITensorNetworks._mps_partition_inds_order</code></a></li><li><a href="#ITensorNetworks._noncommoninds-Tuple{DataGraph}"><code>ITensorNetworks._noncommoninds</code></a></li><li><a href="#ITensorNetworks._optcontract-Tuple{Vector}"><code>ITensorNetworks._optcontract</code></a></li><li><a href="#ITensorNetworks._rem_leaf_vertices!-Tuple{ITensorNetwork}"><code>ITensorNetworks._rem_leaf_vertices!</code></a></li><li><a href="#ITensorNetworks._rem_vertex!-Tuple{ITensorNetworks._DensityMartrixAlgGraph, Any}"><code>ITensorNetworks._rem_vertex!</code></a></li><li><a href="#ITensorNetworks._root-Union{Tuple{var&quot;##337&quot;}, Tuple{Type{Graphs.IsDirected{var&quot;##337&quot;}}, var&quot;##337&quot;}} where var&quot;##337&quot;&lt;:Graphs.AbstractGraph"><code>ITensorNetworks._root</code></a></li><li><a href="#ITensorNetworks._root_union!-Tuple{DataStructures.DisjointSets, Any, Any}"><code>ITensorNetworks._root_union!</code></a></li><li><a href="#ITensorNetworks._sim-Tuple{ITensors.ITensor, Any}"><code>ITensorNetworks._sim</code></a></li><li><a href="#ITensorNetworks._update!-Tuple{ITensorNetworks._DensityMatrixAlgCaches, NamedGraphs.NamedEdge, Vector, Vector{ITensors.ITensor}, Any}"><code>ITensorNetworks._update!</code></a></li><li><a href="#ITensorNetworks.alternating_update-Tuple{Any, Vector{&lt;:ITensorNetworks.AbstractTreeTensorNetwork}, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensorNetworks.alternating_update</code></a></li><li><a href="#ITensorNetworks.approx_itensornetwork-Tuple{NDTensors.Algorithm{:density_matrix}, ITensorNetwork, DataGraph}"><code>ITensorNetworks.approx_itensornetwork</code></a></li><li><a href="#ITensorNetworks.approx_itensornetwork"><code>ITensorNetworks.approx_itensornetwork</code></a></li><li><a href="#ITensorNetworks.approx_itensornetwork-Tuple{NDTensors.Algorithm{:density_matrix}, DataGraph}"><code>ITensorNetworks.approx_itensornetwork</code></a></li><li><a href="#ITensorNetworks.approx_network_region-Tuple{ITensorNetwork, DataGraph, Vector}"><code>ITensorNetworks.approx_network_region</code></a></li><li><a href="#ITensorNetworks.belief_propagation_iteration-Tuple{ITensorNetwork, DataGraph}"><code>ITensorNetworks.belief_propagation_iteration</code></a></li><li><a href="#ITensorNetworks.binary_tree_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks.binary_tree_structure</code></a></li><li><a href="#ITensorNetworks.binary_tree_structure-Tuple{ITensorNetwork}"><code>ITensorNetworks.binary_tree_structure</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:tree_sa}, Any}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:kahypar_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:greedy}, Vector{ITensors.ITensor}}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:sa_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a></li><li><a href="#ITensorNetworks.contraction_sequence_to_graph-Tuple{Any}"><code>ITensorNetworks.contraction_sequence_to_graph</code></a></li><li><a href="#ITensorNetworks.contraction_tree_leaf_bipartition-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.contraction_tree_leaf_bipartition</code></a></li><li><a href="#ITensorNetworks.current_partitioning_backend-Tuple{}"><code>ITensorNetworks.current_partitioning_backend</code></a></li><li><a href="#ITensorNetworks.delta_network-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.delta_network</code></a></li><li><a href="#ITensorNetworks.distance_from_roots-Tuple{Graphs.AbstractGraph, Int64}"><code>ITensorNetworks.distance_from_roots</code></a></li><li><a href="#ITensorNetworks.distance_to_leaf-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.distance_to_leaf</code></a></li><li><a href="#ITensorNetworks.fidelity-Tuple{Vector{ITensors.ITensor}, Vararg{ITensors.ITensor, 5}}"><code>ITensorNetworks.fidelity</code></a></li><li><a href="#ITensorNetworks.fill_contraction_sequence_graph_vertices!-Tuple{Any, Any, Any}"><code>ITensorNetworks.fill_contraction_sequence_graph_vertices!</code></a></li><li><a href="#ITensorNetworks.find_subgraph-Tuple{Any, DataGraph}"><code>ITensorNetworks.find_subgraph</code></a></li><li><a href="#ITensorNetworks.findall_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_edges</code></a></li><li><a href="#ITensorNetworks.findall_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_vertices</code></a></li><li><a href="#ITensorNetworks.findfirst_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_edges</code></a></li><li><a href="#ITensorNetworks.findfirst_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_vertices</code></a></li><li><a href="#ITensorNetworks.finite_state_machine-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.finite_state_machine</code></a></li><li><a href="#ITensorNetworks.fsmTTN-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.fsmTTN</code></a></li><li><a href="#ITensorNetworks.get_environment-Tuple{ITensorNetwork, DataGraph, Vector}"><code>ITensorNetworks.get_environment</code></a></li><li><a href="#ITensorNetworks.has_leaf_neighbor-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.has_leaf_neighbor</code></a></li><li><a href="#ITensorNetworks.heisenberg-Tuple{Integer}"><code>ITensorNetworks.heisenberg</code></a></li><li><a href="#ITensorNetworks.heisenberg-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.heisenberg</code></a></li><li><a href="#ITensorNetworks.internal_edges-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.internal_edges</code></a></li><li><a href="#ITensorNetworks.is_leaf_edge-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.is_leaf_edge</code></a></li><li><a href="#ITensorNetworks.ising-Tuple{Integer}"><code>ITensorNetworks.ising</code></a></li><li><a href="#ITensorNetworks.ising-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.ising</code></a></li><li><a href="#ITensorNetworks.ising_network-Tuple{Type, IndsNetwork, Number}"><code>ITensorNetworks.ising_network</code></a></li><li><a href="#ITensorNetworks.ising_network_state-Tuple{Type, IndsNetwork, Number}"><code>ITensorNetworks.ising_network_state</code></a></li><li><a href="#ITensorNetworks.nested_graph_leaf_vertices-Tuple{Any}"><code>ITensorNetworks.nested_graph_leaf_vertices</code></a></li><li><a href="#ITensorNetworks.optimise_p_q-Tuple{ITensors.ITensor, ITensors.ITensor, Vector{ITensors.ITensor}, ITensors.ITensor}"><code>ITensorNetworks.optimise_p_q</code></a></li><li><a href="#ITensorNetworks.partition-Tuple{NDTensors.Algorithm{:mincut_recursive_bisection}, ITensorNetwork, DataGraph}"><code>ITensorNetworks.partition</code></a></li><li><a href="#ITensorNetworks.partition-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition</code></a></li><li><a href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition_vertices</code></a></li><li><a href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.partition_vertices</code></a></li><li><a href="#ITensorNetworks.path_graph_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks.path_graph_structure</code></a></li><li><a href="#ITensorNetworks.path_graph_structure-Tuple{ITensorNetwork}"><code>ITensorNetworks.path_graph_structure</code></a></li><li><a href="#ITensorNetworks.randomITensorNetwork-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.randomITensorNetwork</code></a></li><li><a href="#ITensorNetworks.randomITensorNetwork-Tuple{Distributions.Distribution, IndsNetwork}"><code>ITensorNetworks.randomITensorNetwork</code></a></li><li><a href="#ITensorNetworks.relabel_sites-Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, Dictionaries.AbstractDictionary}"><code>ITensorNetworks.relabel_sites</code></a></li><li><a href="#ITensorNetworks.set_partitioning_backend!-Tuple{Union{Missing, String, ITensorNetworks.Backend}}"><code>ITensorNetworks.set_partitioning_backend!</code></a></li><li><a href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.subgraphs</code></a></li><li><a href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.subgraphs</code></a></li><li><a href="#ITensorNetworks.svdTTN-Union{Tuple{VT}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{VT, &lt;:ITensors.Index}, VT}} where {C, VT}"><code>ITensorNetworks.svdTTN</code></a></li><li><a href="#ITensorNetworks.symmetric_gauge-Tuple{ITensorNetwork}"><code>ITensorNetworks.symmetric_gauge</code></a></li><li><a href="#ITensorNetworks.tdvp-Tuple{Any, Number, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensorNetworks.tdvp</code></a></li><li><a href="#ITensorNetworks.to_vec-Tuple{Any}"><code>ITensorNetworks.to_vec</code></a></li><li><a href="#ITensorNetworks.update_message_tensor-Tuple{ITensorNetwork, Vector, Vector{ITensorNetwork}}"><code>ITensorNetworks.update_message_tensor</code></a></li><li><a href="#ITensors.apply-Tuple{ITensorNetworks.AbstractTreeTensorNetwork, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensors.apply</code></a></li><li><a href="#ITensors.dmrg-Tuple{Any, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensors.dmrg</code></a></li><li><a href="#ITensors.replaceinds-Tuple{ITensors.ITensor, Dict{&lt;:ITensors.Index, &lt;:ITensors.Index}}"><code>ITensors.replaceinds</code></a></li><li><a href="#KrylovKit.eigsolve-Tuple{Any, ITensorNetworks.AbstractTreeTensorNetwork}"><code>KrylovKit.eigsolve</code></a></li><li><a href="#KrylovKit.linsolve"><code>KrylovKit.linsolve</code></a></li><li><a href="#NDTensors.contract-Tuple{ITensorNetworks.AbstractTreeTensorNetwork, ITensorNetworks.AbstractTreeTensorNetwork}"><code>NDTensors.contract</code></a></li><li><a href="#Observers.update!-Tuple{Nothing}"><code>Observers.update!</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.CURRENT_PARTITIONING_BACKEND" href="#ITensorNetworks.CURRENT_PARTITIONING_BACKEND"><code>ITensorNetworks.CURRENT_PARTITIONING_BACKEND</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Current default graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L14-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.Backend" href="#ITensorNetworks.Backend"><code>ITensorNetworks.Backend</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ITensorNetwork" href="#ITensorNetworks.ITensorNetwork"><code>ITensorNetworks.ITensorNetwork</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ITensorNetwork</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/itensornetwork.jl#L3-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ProjTTN" href="#ITensorNetworks.ProjTTN"><code>ITensorNetworks.ProjTTN</code></a> — <span class="docstring-category">Type</span></header><section><div><p>ProjTTN</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/projttns/projttn.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ProjTTNSum" href="#ITensorNetworks.ProjTTNSum"><code>ITensorNetworks.ProjTTNSum</code></a> — <span class="docstring-category">Type</span></header><section><div><p>ProjTTNSum</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/projttns/projttnsum.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.SweepStep" href="#ITensorNetworks.SweepStep"><code>ITensorNetworks.SweepStep</code></a> — <span class="docstring-category">Type</span></header><section><div><p>struct SweepStep{V}</p><p>Auxiliary object specifying a single local update step in a tree sweeping algorithm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/tree_sweeping.jl#L5-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.TDVPInfo" href="#ITensorNetworks.TDVPInfo"><code>ITensorNetworks.TDVPInfo</code></a> — <span class="docstring-category">Type</span></header><section><div><p>#fields</p><ul><li><code>maxtruncerr::Float64</code>: the maximum tuncation error</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/tdvpinfo.jl#L1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.TTN-Union{Tuple{V}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, IndsNetwork{V, &lt;:ITensors.Index}}} where V" href="#ITensorNetworks.TTN-Union{Tuple{V}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, IndsNetwork{V, &lt;:ITensors.Index}}} where V"><code>ITensorNetworks.TTN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">TTN(os::OpSum, sites::IndsNetwork{&lt;:Index}; kwargs...)
TTN(eltype::Type{&lt;:Number}, os::OpSum, sites::IndsNetwork{&lt;:Index}; kwargs...)</code></pre><p>Convert an OpSum object <code>os</code> to a TreeTensorNetwork, with indices given by <code>sites</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/opsum_to_ttn.jl#L511-L516">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.TreeTensorNetwork" href="#ITensorNetworks.TreeTensorNetwork"><code>ITensorNetworks.TreeTensorNetwork</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TreeTensorNetwork{V} &lt;: AbstractTreeTensorNetwork{V}</code></pre><p><strong>Fields</strong></p><ul><li>itensor_network::ITensorNetwork{V}</li><li>ortho_lims::Vector{V}: A vector of vertices defining the orthogonality limits.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/ttn.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._DensityMartrixAlgGraph" href="#ITensorNetworks._DensityMartrixAlgGraph"><code>ITensorNetworks._DensityMartrixAlgGraph</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The struct stores data used in the density matrix algorithm.   partition: The given tn partition   out<em>tree: the binary tree structure of the output ITensorNetwork   root: root vertex of the bfs</em>tree for truncation   innerinds<em>to</em>sim: mapping each inner index of the tn represented by <code>partition</code> to a sim index   caches: all the cached density matrices</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L117-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._DensityMatrixAlgCaches" href="#ITensorNetworks._DensityMatrixAlgCaches"><code>ITensorNetworks._DensityMatrixAlgCaches</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The struct contains cached density matrices and cached partial density matrices for each edge / set of edges in the tensor network.</p><p>Density matrix example:   Consider a tensor network below,     1     /9  2   /   /3  6     /|  /4 5 7  8   /  | |   The density matrix for the edge <code>NamedEdge(2, 3)</code> squares the subgraph with vertices 3, 4, 5      |      3     /|    4 5    | |    4 5    |/    3    |   The density matrix for the edge <code>NamedEdge(5, 3)</code> squares the subgraph     with vertices 1, 2, 3, 4, 6, 7, 8, 9       1       //  2     /   //   3  6   9   /|  /|  4   7  8   |  |   |  |   |  4   7  8   |  |/  | /   |  3   6   |  |  /   |  | /   |  2   9 /   |/   1   The density matrix for the edge <code>NamedEdge(4, 3)</code> squares the subgraph     with vertices 1, 2, 3, 5, 6, 7, 8, 9       1       //  2     /   //   3  6   9   /|  /|    5 7  8   |    | |  |   |    5 7  8   |  |/  | /   |  3   6   |  |  /   |  | /   |  2   9 /   |/   1</p><p>Partial density matrix example:   Consider a tensor network below,     1     /9  2   /   /3  6     /|  /4 5 7  8   /  | |   The partial density matrix for the Edge set <code>Set([NamedEdge(2, 3), NamedEdge(5, 3)])</code>     squares the subgraph with vertices 4, and contract with the tensor 3     |     3    /   4 - 4 -   The partial density matrix for the Edge set <code>Set([NamedEdge(4, 3), NamedEdge(5, 3)])</code>     squares the subgraph with vertices 1, 2, 6, 7, 8, 9, and contract with the tensor 3       1       //  2     /   //   3  6   9   /|  /|      7  8   |      |  |   |      7  8   |      | /   |      6   |     /   |  | /   |  2   9 /   |/   1   The density matrix for the Edge set <code>Set([NamedEdge(4, 3), NamedEdge(2, 3)])</code>     squares the subgraph with vertices 5. and contract with the tensor 3     |     3    /   5 - 5 -</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L1-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._approx_binary_tree_itensornetwork!-Tuple{DataGraph, NamedGraphs.NamedGraph}" href="#ITensorNetworks._approx_binary_tree_itensornetwork!-Tuple{DataGraph, NamedGraphs.NamedGraph}"><code>ITensorNetworks._approx_binary_tree_itensornetwork!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Approximate a <code>partition</code> into an output ITensorNetwork with the binary tree structure defined by <code>out_tree</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L382-L385">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._binary_tree_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}" href="#ITensorNetworks._binary_tree_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._binary_tree_structure</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a tn and outinds (a subset of noncommoninds of tn), get a <code>DataGraph</code> with binary tree structure of outinds that will be used in the binary tree partition. If maximally_unbalanced=true, the binary tree will have a line/mps structure. The binary tree is recursively constructed from leaves to the root.</p><p>Example:</p><p><strong>TODO</strong></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L119-L127">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._contract_deltas-Tuple{ITensorNetwork}" href="#ITensorNetworks._contract_deltas-Tuple{ITensorNetwork}"><code>ITensorNetworks._contract_deltas</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given an input tensor network <code>tn</code>, remove redundent delta tensors in <code>tn</code> and change inds accordingly to make the output <code>tn</code> represent the same tensor network but with less delta tensors.</p><p>======== Example:   julia&gt; is = [Index(2, string(i)) for i in 1:6]   julia&gt; a = ITensor(is[1], is[2])   julia&gt; b = ITensor(is[2], is[3])   julia&gt; delta1 = delta(is[3], is[4])   julia&gt; delta2 = delta(is[5], is[6])   julia&gt; tn = ITensorNetwork([a, b, delta1, delta2])   julia&gt; ITensorNetworks.<em>contract</em>deltas(tn)   ITensorNetwork{Int64} with 3 vertices:   3-element Vector{Int64}:    1    2    4</p><p>and 1 edge(s):   1 =&gt; 2</p><p>with vertex data:   3-element Dictionaries.Dictionary{Int64, Any}    1 │ ((dim=2|id=457|&quot;1&quot;), (dim=2|id=296|&quot;2&quot;))    2 │ ((dim=2|id=296|&quot;2&quot;), (dim=2|id=613|&quot;4&quot;))    4 │ ((dim=2|id=626|&quot;6&quot;), (dim=2|id=237|&quot;5&quot;))</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contract_deltas.jl#L55-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._contract_deltas_ignore_leaf_partitions-Tuple{DataGraph}" href="#ITensorNetworks._contract_deltas_ignore_leaf_partitions-Tuple{DataGraph}"><code>ITensorNetworks._contract_deltas_ignore_leaf_partitions</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given an input <code>partition</code>, contract redundent delta tensors of non-leaf vertices in <code>partition</code> without changing the tensor network value. <code>root</code> is the root of the dfs_tree that defines the leaves. Note: for each vertex <code>v</code> of <code>partition</code>, the number of non-delta tensors   in <code>partition[v]</code> will not be changed. Note: only delta tensors of non-leaf vertices will be contracted. Note: this function assumes that all noncommoninds of the partition are in leaf partitions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contract_deltas.jl#L116-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._delta_inds_disjointsets-Tuple{Vector{&lt;:ITensors.ITensor}, Vector{&lt;:ITensors.Index}}" href="#ITensorNetworks._delta_inds_disjointsets-Tuple{Vector{&lt;:ITensors.ITensor}, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._delta_inds_disjointsets</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a list of delta tensors <code>deltas</code>, return a <code>DisjointSets</code> of all its indices such that each pair of indices adjacent to any delta tensor must be in the same disjoint set. If a disjoint set contains indices in <code>rootinds</code>, then one of such indices in <code>rootinds</code> must be the root of this set.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contract_deltas.jl#L31-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._densitymatrix_outinds_to_sim-Tuple{Any, Any}" href="#ITensorNetworks._densitymatrix_outinds_to_sim-Tuple{Any, Any}"><code>ITensorNetworks._densitymatrix_outinds_to_sim</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Returns a dict that maps the partition&#39;s outinds that are adjacent to <code>partition[root]</code> to siminds</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L174-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._distance-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}" href="#ITensorNetworks._distance-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Sum of shortest path distances among all outinds.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L76-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._introot_union!-Tuple{DataStructures.IntDisjointSets, Any, Any}" href="#ITensorNetworks._introot_union!-Tuple{DataStructures.IntDisjointSets, Any, Any}"><code>ITensorNetworks._introot_union!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Rewrite of the function   <code>DataStructures.root_union!(s::IntDisjointSet{T}, x::T, y::T) where {T&lt;:Integer}</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contract_deltas.jl#L1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._maxweightoutinds_tn-Tuple{ITensorNetwork, Union{Nothing, Vector{&lt;:ITensors.Index}}}" href="#ITensorNetworks._maxweightoutinds_tn-Tuple{ITensorNetwork, Union{Nothing, Vector{&lt;:ITensors.Index}}}"><code>ITensorNetworks._maxweightoutinds_tn</code></a> — <span class="docstring-category">Method</span></header><section><div><p>create a tn with empty ITensors whose outinds weights are MAX<em>WEIGHT The maxweight</em>tn is constructed so that only commoninds of the tn will be considered in mincut.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L97-L101">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._mincut-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}, Vector{&lt;:ITensors.Index}}" href="#ITensorNetworks._mincut-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._mincut</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Calculate the mincut between two subsets of the uncontracted inds (source<em>inds and terminal</em>inds) of the input tn. Mincut of two inds list is defined as the mincut of two newly added vertices, each one neighboring to one inds subset.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L34-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._mincut_inds-Tuple{Pair{&lt;:ITensorNetwork, &lt;:ITensorNetwork}, Dict{ITensors.Index, ITensors.Index}, Vector{&lt;:Vector{&lt;:ITensors.Index}}}" href="#ITensorNetworks._mincut_inds-Tuple{Pair{&lt;:ITensorNetwork, &lt;:ITensorNetwork}, Dict{ITensors.Index, ITensors.Index}, Vector{&lt;:Vector{&lt;:ITensors.Index}}}"><code>ITensorNetworks._mincut_inds</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find a vector of indices within sourceinds<em>list yielding the mincut of given tn</em>pair. Args:   tn<em>pair: a pair of tns (tn1 =&gt; tn2), where tn2 is generated via _maxweightoutinds</em>tn(tn1)   out<em>to</em>maxweight<em>ind: a dict mapping each out ind in tn1 to out ind in tn2   sourceinds</em>list: a list of vector of indices to be considered Note:   For each sourceinds in sourceinds<em>list, we consider its mincut within both tns (tn1, tn2) given in tn</em>pair.   The mincut in tn1 represents the rank upper bound when splitting sourceinds with other inds in outinds.   The mincut in tn2 represents the rank upper bound when the weights of outinds are very large.   The first mincut upper_bounds the number of non-zero singular values, while the second empirically reveals the   singular value decay.   We output the sourceinds where the first mincut value is the minimum, the secound mincut value is also   the minimum under the condition that the first mincut is optimal, and the sourceinds have the lowest all-pair shortest path.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L238-L252">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._mincut_partitions-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}, Vector{&lt;:ITensors.Index}}" href="#ITensorNetworks._mincut_partitions-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks._mincut_partitions</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Calculate the mincut<em>partitions between two subsets of the uncontracted inds (source</em>inds and terminal_inds) of the input tn.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L54-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._mps_partition_inds_order-Tuple{ITensorNetwork, Union{Nothing, Vector{&lt;:ITensors.Index}}}" href="#ITensorNetworks._mps_partition_inds_order-Tuple{ITensorNetwork, Union{Nothing, Vector{&lt;:ITensors.Index}}}"><code>ITensorNetworks._mps_partition_inds_order</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a tn and outinds, returns a vector of indices representing MPS inds ordering.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L178-L180">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._noncommoninds-Tuple{DataGraph}" href="#ITensorNetworks._noncommoninds-Tuple{DataGraph}"><code>ITensorNetworks._noncommoninds</code></a> — <span class="docstring-category">Method</span></header><section><div><p>TODO: do we want to make it a public function?</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L325-L327">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._optcontract-Tuple{Vector}" href="#ITensorNetworks._optcontract-Tuple{Vector}"><code>ITensorNetworks._optcontract</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Contract of a vector of tensors, <code>network</code>, with a contraction sequence generated via sa_bipartite</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L145-L147">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._rem_leaf_vertices!-Tuple{ITensorNetwork}" href="#ITensorNetworks._rem_leaf_vertices!-Tuple{ITensorNetwork}"><code>ITensorNetworks._rem_leaf_vertices!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>For a given ITensorNetwork <code>tn</code> and a <code>root</code> vertex, remove leaf vertices in the directed tree with root <code>root</code> without changing the tensor represented by tn. In particular, the tensor of each leaf vertex is contracted with the tensor of its parent vertex to keep the tensor unchanged.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L359-L364">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._rem_vertex!-Tuple{ITensorNetworks._DensityMartrixAlgGraph, Any}" href="#ITensorNetworks._rem_vertex!-Tuple{ITensorNetworks._DensityMartrixAlgGraph, Any}"><code>ITensorNetworks._rem_vertex!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Perform truncation and remove <code>root</code> vertex in the <code>partition</code> and <code>out_tree</code> of <code>alg_graph</code>.</p><p>Example:   Consider an <code>alg_graph</code><code>whose</code>out<em>tree<code>is shown below,     1     /9  2   /   /3  6     /|  /4 5 7  8   /  | |   when</code>root = 4<code>, the output</code>out</em>tree<code>will be     1     /9  2   /   /3  6     /|  /5 7  8      | |   and the returned tensor</code>U` will be the projector at vertex 4 in the output tn.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L257-L273">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._root-Union{Tuple{var&quot;##337&quot;}, Tuple{Type{Graphs.IsDirected{var&quot;##337&quot;}}, var&quot;##337&quot;}} where var&quot;##337&quot;&lt;:Graphs.AbstractGraph" href="#ITensorNetworks._root-Union{Tuple{var&quot;##337&quot;}, Tuple{Type{Graphs.IsDirected{var&quot;##337&quot;}}, var&quot;##337&quot;}} where var&quot;##337&quot;&lt;:Graphs.AbstractGraph"><code>ITensorNetworks._root</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Return the root vertex of a rooted directed graph</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/Graphs/abstractgraph.jl#L37-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._root_union!-Tuple{DataStructures.DisjointSets, Any, Any}" href="#ITensorNetworks._root_union!-Tuple{DataStructures.DisjointSets, Any, Any}"><code>ITensorNetworks._root_union!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Rewrite of the function <code>DataStructures.root_union!(s::DisjointSet{T}, x::T, y::T)</code>. The difference is that in the output of <code>_root_union!</code>, x is guaranteed to be the root of y when setting <code>left_root=true</code>, and y will be the root of x when setting <code>left_root=false</code>. In <code>DataStructures.root_union!</code>, the root value cannot be specified. A specified root is useful in functions such as <code>_remove_deltas</code>, where when we union two indices into one disjointset, we want the index that is the outinds if the given tensor network to always be the root in the DisjointSets.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contract_deltas.jl#L18-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._sim-Tuple{ITensors.ITensor, Any}" href="#ITensorNetworks._sim-Tuple{ITensors.ITensor, Any}"><code>ITensorNetworks._sim</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Replace the inds of partial<em>dm</em>tensor that are in keys of <code>inds_to_siminds</code> to the corresponding value, and replace the inds that are in values of <code>inds_to_siminds</code> to the corresponding key.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L184-L188">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks._update!-Tuple{ITensorNetworks._DensityMatrixAlgCaches, NamedGraphs.NamedEdge, Vector, Vector{ITensors.ITensor}, Any}" href="#ITensorNetworks._update!-Tuple{ITensorNetworks._DensityMatrixAlgCaches, NamedGraphs.NamedEdge, Vector, Vector{ITensors.ITensor}, Any}"><code>ITensorNetworks._update!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Update <code>caches.e_to_dm[e]</code> and <code>caches.es_to_pdm[es]</code>.   caches: the caches of the density matrix algorithm.   edge: the edge defining the density matrix   children: the children vertices of <code>dst(edge)</code> in the dfs<em>tree   network: the tensor network at vertex <code>dst(edge)</code>   inds</em>to_sim: a dict mapping inds to sim inds</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L201-L208">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.alternating_update-Tuple{Any, Vector{&lt;:ITensorNetworks.AbstractTreeTensorNetwork}, ITensorNetworks.AbstractTreeTensorNetwork}" href="#ITensorNetworks.alternating_update-Tuple{Any, Vector{&lt;:ITensorNetworks.AbstractTreeTensorNetwork}, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensorNetworks.alternating_update</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tdvp(Hs::Vector{MPO},psi0::MPS,t::Number; kwargs...)
tdvp(Hs::Vector{MPO},psi0::MPS,t::Number, sweeps::Sweeps; kwargs...)</code></pre><p>Use the time dependent variational principle (TDVP) algorithm to compute <code>exp(t*H)*psi0</code> using an efficient algorithm based on alternating optimization of the MPS tensors and local Krylov exponentiation of H.</p><p>This version of <code>tdvp</code> accepts a representation of H as a Vector of MPOs, Hs = [H1,H2,H3,...] such that H is defined as H = H1+H2+H3+... Note that this sum of MPOs is not actually computed; rather the set of MPOs [H1,H2,H3,..] is efficiently looped over at  each step of the algorithm when optimizing the MPS.</p><p>Returns:</p><ul><li><code>psi::MPS</code> - time-evolved MPS</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/alternating_update.jl#L116-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.approx_itensornetwork" href="#ITensorNetworks.approx_itensornetwork"><code>ITensorNetworks.approx_itensornetwork</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Approximate a given ITensorNetwork <code>tn</code> into an output ITensorNetwork with <code>output_structure</code>. <code>output_structure</code> outputs a directed binary tree DataGraph defining the desired graph structure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L457-L460">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.approx_itensornetwork-Tuple{NDTensors.Algorithm{:density_matrix}, DataGraph}" href="#ITensorNetworks.approx_itensornetwork-Tuple{NDTensors.Algorithm{:density_matrix}, DataGraph}"><code>ITensorNetworks.approx_itensornetwork</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Approximate a <code>binary_tree_partition</code> into an output ITensorNetwork with the same binary tree structure. <code>root</code> is the root vertex of the pre-order depth-first-search traversal used to perform the truncations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L423-L427">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.approx_itensornetwork-Tuple{NDTensors.Algorithm{:density_matrix}, ITensorNetwork, DataGraph}" href="#ITensorNetworks.approx_itensornetwork-Tuple{NDTensors.Algorithm{:density_matrix}, ITensorNetwork, DataGraph}"><code>ITensorNetworks.approx_itensornetwork</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Approximate a given ITensorNetwork <code>tn</code> into an output ITensorNetwork with a binary tree structure. The binary tree structure is defined based on <code>inds_btree</code>, which is a directed binary tree DataGraph of indices.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/approx_itensornetwork.jl#L482-L486">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.approx_network_region-Tuple{ITensorNetwork, DataGraph, Vector}" href="#ITensorNetworks.approx_network_region-Tuple{ITensorNetwork, DataGraph, Vector}"><code>ITensorNetworks.approx_network_region</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Calculate the contraction of a tensor network centred on the vertices verts. Using message tensors. Defaults to using tn[verts] as the local network but can be overriden</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/beliefpropagation.jl#L130-L133">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.belief_propagation_iteration-Tuple{ITensorNetwork, DataGraph}" href="#ITensorNetworks.belief_propagation_iteration-Tuple{ITensorNetwork, DataGraph}"><code>ITensorNetworks.belief_propagation_iteration</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Do an update of all message tensors for a given ITensornetwork and its partition into sub graphs</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/beliefpropagation.jl#L64-L66">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.binary_tree_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}" href="#ITensorNetworks.binary_tree_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks.binary_tree_structure</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a <code>tn</code> and <code>outinds</code> (a subset of noncommoninds of <code>tn</code>), outputs a directed binary tree DataGraph of <code>outinds</code> defining the desired graph structure</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L26-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.binary_tree_structure-Tuple{ITensorNetwork}" href="#ITensorNetworks.binary_tree_structure-Tuple{ITensorNetwork}"><code>ITensorNetworks.binary_tree_structure</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Outputs a directed binary tree DataGraph defining the desired graph structure</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:greedy}, Vector{ITensors.ITensor}}" href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:greedy}, Vector{ITensors.ITensor}}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GreedyMethod(; method=MinSpaceOut(), nrepeat=10)</code></pre><p>The fast but poor greedy optimizer. Input arguments are:</p><ul><li><code>method</code> is <code>MinSpaceDiff()</code> or <code>MinSpaceOut</code>.<ul><li><code>MinSpaceOut</code> choose one of the contraction that produces a minimum output tensor size,</li><li><code>MinSpaceDiff</code> choose one of the contraction that decrease the space most.</li></ul></li><li><code>nrepeat</code> is the number of repeatition, returns the best contraction order.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contraction_sequences.jl#L19-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:kahypar_bipartite}, Any}" href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:kahypar_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">KaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),
                   max_group_size=40, greedy_config=GreedyMethod())</code></pre><p>Optimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are:</p><ul><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>imbalances</code> is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>greedy_config</code> is a greedy optimizer.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li><li><a href="https://arxiv.org/abs/2103.03074">Simulating the Sycamore quantum supremacy circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contraction_sequences.jl#L94-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:sa_bipartite}, Any}" href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:sa_bipartite}, Any}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">SABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000
              max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)</code></pre><p>Optimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are:</p><ul><li><code>size_dict</code>, a dictionary that specifies leg dimensions,</li><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>βs</code> is a list of inverse temperature <code>1/T</code>,</li><li><code>niters</code> is the number of iteration in each temperature,</li><li><code>ntrials</code> is the number of repetition (with different random seeds),</li><li><code>greedy_config</code> configures the greedy method,</li><li><code>initializer</code>, the partition configuration initializer, one can choose <code>:random</code> or <code>:greedy</code> (slow but better).</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contraction_sequences.jl#L64-L84">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:tree_sa}, Any}" href="#ITensorNetworks.contraction_sequence-Tuple{NDTensors.Algorithm{:tree_sa}, Any}"><code>ITensorNetworks.contraction_sequence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">TreeSA(; sc_target=20, βs=collect(0.01:0.05:15), ntrials=10, niters=50,
         sc_weight=1.0, rw_weight=0.2, initializer=:greedy, greedy_config=GreedyMethod(; nrepeat=1))</code></pre><p>Optimize the einsum contraction pattern using the simulated annealing on tensor expression tree.</p><ul><li><code>sc_target</code> is the target space complexity,</li><li><code>ntrials</code>, <code>βs</code> and <code>niters</code> are annealing parameters, doing <code>ntrials</code> indepedent annealings, each has inverse tempteratures specified by <code>βs</code>, in each temperature, do <code>niters</code> updates of the tree.</li><li><code>sc_weight</code> is the relative importance factor of space complexity in the loss compared with the time complexity.</li><li><code>rw_weight</code> is the relative importance factor of memory read and write in the loss compared with the time complexity.</li><li><code>initializer</code> specifies how to determine the initial configuration, it can be <code>:greedy</code> or <code>:random</code>. If it is using <code>:greedy</code> method to generate the initial configuration, it also uses two extra arguments <code>greedy_method</code> and <code>greedy_nrepeat</code>.</li><li><code>nslices</code> is the number of sliced legs, default is 0.</li><li><code>fixed_slices</code> is a vector of sliced legs, default is <code>[]</code>.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2108.05665">Recursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contraction_sequences.jl#L38-L54">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_sequence_to_graph-Tuple{Any}" href="#ITensorNetworks.contraction_sequence_to_graph-Tuple{Any}"><code>ITensorNetworks.contraction_sequence_to_graph</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Take a contraction<em>sequence and return a graphical representation of it. The leaves of the graph represent the leaves of the sequence whilst the internal</em>nodes of the graph define a tripartition of the graph and thus are named as an n = 3 element tuples, which each element specifying the keys involved. Edges connect parents/children within the contraction sequence.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contraction_tree_to_graph.jl#L2-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.contraction_tree_leaf_bipartition-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.contraction_tree_leaf_bipartition-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.contraction_tree_leaf_bipartition</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Get the vertex bi-partition that a given edge represents</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contraction_tree_to_graph.jl#L51">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.current_partitioning_backend-Tuple{}" href="#ITensorNetworks.current_partitioning_backend-Tuple{}"><code>ITensorNetworks.current_partitioning_backend</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Get the graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.delta_network-Tuple{Type, IndsNetwork}" href="#ITensorNetworks.delta_network-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.delta_network</code></a> — <span class="docstring-category">Method</span></header><section><div><p>RETURN A TENSOR NETWORK WITH COPY TENSORS ON EACH VERTEX.  Note that passing a link_space will mean the indices of the resulting network don&#39;t match those of the input indsnetwork</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/specialitensornetworks.jl#L1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.distance_from_roots-Tuple{Graphs.AbstractGraph, Int64}" href="#ITensorNetworks.distance_from_roots-Tuple{Graphs.AbstractGraph, Int64}"><code>ITensorNetworks.distance_from_roots</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Return all vertices which are within a certain pathlength <code>dist</code> of the leaves of the  graph</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/Graphs/abstractgraph.jl#L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.distance_to_leaf-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.distance_to_leaf-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.distance_to_leaf</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Get distance of a vertex from a leaf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/Graphs/abstractgraph.jl#L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.fidelity-Tuple{Vector{ITensors.ITensor}, Vararg{ITensors.ITensor, 5}}" href="#ITensorNetworks.fidelity-Tuple{Vector{ITensors.ITensor}, Vararg{ITensors.ITensor, 5}}"><code>ITensorNetworks.fidelity</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Calculate the overlap of the gate acting on the previous p and q versus the new p and q in the presence of environments. This is the cost function that optimise<em>p</em>q will minimise</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/apply.jl#L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.fill_contraction_sequence_graph_vertices!-Tuple{Any, Any, Any}" href="#ITensorNetworks.fill_contraction_sequence_graph_vertices!-Tuple{Any, Any, Any}"><code>ITensorNetworks.fill_contraction_sequence_graph_vertices!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a contraction sequence which is a subsequence of some larger sequence (with leaves <code>leaves</code>) which is being built on g Spawn <code>contract sequence&#39; as a vertex on</code>current_g&#39; and continue on with its children </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/contraction_tree_to_graph.jl#L36-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.find_subgraph-Tuple{Any, DataGraph}" href="#ITensorNetworks.find_subgraph-Tuple{Any, DataGraph}"><code>ITensorNetworks.find_subgraph</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the subgraph which contains the specified vertex.</p><p>TODO: Rename something more general, like:</p><p>findfirst<em>in</em>vertex_data(item, graph::AbstractDataGraph)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L191-L197">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findall_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findall_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_edges</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find all edges <code>e</code> such that <code>f(graph[e]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L177-L179">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findall_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findall_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findall_on_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find all vertices <code>v</code> such that <code>f(graph[v]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L163-L165">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findfirst_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findfirst_on_edges-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_edges</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the edge <code>e</code> such that <code>f(graph[e]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L184-L186">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.findfirst_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}" href="#ITensorNetworks.findfirst_on_vertices-Tuple{Function, DataGraphs.AbstractDataGraph}"><code>ITensorNetworks.findfirst_on_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the vertex <code>v</code> such that <code>f(graph[v]) == true</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L170-L172">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.finite_state_machine-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}" href="#ITensorNetworks.finite_state_machine-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.finite_state_machine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">finite_state_machine(os::OpSum{C}, sites::IndsNetwork{V,&lt;:Index}, root_vertex::V) where {C,V}</code></pre><p>Finite state machine generator for ITensors.OpSum Hamiltonian defined on a tree graph. The site Index graph must be a tree graph, and the chosen root  must be a leaf vertex of this tree. Returns a DataGraph of SparseArrayKit.SparseArrays</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/opsum_to_ttn.jl#L46-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.fsmTTN-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}" href="#ITensorNetworks.fsmTTN-Union{Tuple{V}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{V, &lt;:ITensors.Index}, V}} where {C, V}"><code>ITensorNetworks.fsmTTN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fsmTTN(os::OpSum{C}, sites::IndsNetwork{V,&lt;:Index}, root_vertex::V, kwargs...) where {C,V}</code></pre><p>Construct a dense TreeTensorNetwork from sparse finite state machine represenatation, without compression.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/opsum_to_ttn.jl#L177-L182">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.get_environment-Tuple{ITensorNetwork, DataGraph, Vector}" href="#ITensorNetworks.get_environment-Tuple{ITensorNetwork, DataGraph, Vector}"><code>ITensorNetworks.get_environment</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a subet of vertices of a given Tensor Network and the Message Tensors for that network, return a Dictionary with the involved subgraphs as keys and the vector of tensors associated with that subgraph as values Specifically, the contraction of the environment tensors and tn[vertices] will be a scalar.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/beliefpropagation.jl#L112-L115">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.has_leaf_neighbor-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.has_leaf_neighbor-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.has_leaf_neighbor</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Determine if a node has any neighbors which are leaves</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/Graphs/abstractgraph.jl#L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.heisenberg-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.heisenberg-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.heisenberg</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Random field J1-J2 Heisenberg model on a general graph</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/models.jl#L4-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.heisenberg-Tuple{Integer}" href="#ITensorNetworks.heisenberg-Tuple{Integer}"><code>ITensorNetworks.heisenberg</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Random field J1-J2 Heisenberg model on a chain of length N</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/models.jl#L68-L70">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.internal_edges-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.internal_edges-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.internal_edges</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Get all edges which do not involve a leaf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/Graphs/abstractgraph.jl#L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.is_leaf_edge-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.is_leaf_edge-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.is_leaf_edge</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Determine if an edge involves a leaf (at src or dst)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/Graphs/abstractgraph.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.ising-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.ising</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Next-to-nearest-neighbor Ising model (ZZX) on a general graph</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/models.jl#L38-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising-Tuple{Integer}" href="#ITensorNetworks.ising-Tuple{Integer}"><code>ITensorNetworks.ising</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Next-to-nearest-neighbor Ising model (ZZX) on a chain of length N</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/models.jl#L73-L75">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising_network-Tuple{Type, IndsNetwork, Number}" href="#ITensorNetworks.ising_network-Tuple{Type, IndsNetwork, Number}"><code>ITensorNetworks.ising_network</code></a> — <span class="docstring-category">Method</span></header><section><div><p>BUILD Z OF CLASSICAL ISING MODEL ON A GIVEN GRAPH AT INVERSE TEMP BETA H = -\sum<em>{(v,v&#39;) \in edges}\sigma^{z}</em>{v}\sigma^{z}_{v&#39;} OPTIONAL ARGUMENT:   h: EXTERNAL MAGNETIC FIELD   szverts: A LIST OF VERTICES OVER WHICH TO APPLY A SZ.     THE RESULTANT NETWORK CAN THEN BE CONTRACTED AND DIVIDED BY THE ACTUAL PARTITION FUNCTION TO GET THAT OBSERVABLE     INDSNETWORK IS ASSUMED TO BE BUILT FROM A GRAPH (NO SITE INDS) AND OF LINK SPACE 2</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/specialitensornetworks.jl#L21-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.ising_network_state-Tuple{Type, IndsNetwork, Number}" href="#ITensorNetworks.ising_network_state-Tuple{Type, IndsNetwork, Number}"><code>ITensorNetworks.ising_network_state</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build the wavefunction whose norm is equal to Z of the classical ising model s needs to have site indices in this case!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/specialitensornetworks.jl#L77-L79">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.nested_graph_leaf_vertices-Tuple{Any}" href="#ITensorNetworks.nested_graph_leaf_vertices-Tuple{Any}"><code>ITensorNetworks.nested_graph_leaf_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a nested graph fetch all the vertices down to the lowest levels and return the grouping at the highest level. Keyword argument is used to state whether we are at the top</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L306-L308">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.optimise_p_q-Tuple{ITensors.ITensor, ITensors.ITensor, Vector{ITensors.ITensor}, ITensors.ITensor}" href="#ITensorNetworks.optimise_p_q-Tuple{ITensors.ITensor, ITensors.ITensor, Vector{ITensors.ITensor}, ITensors.ITensor}"><code>ITensorNetworks.optimise_p_q</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Do Full Update Sweeping, Optimising the tensors p and q in the presence of the environments envs, Specifically this functions find the p<em>cur and q</em>cur which optimise envs<em>gate</em>p<em>q</em>dag(prime(p<em>cur))*dag(prime(q</em>cur))</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/apply.jl#L188-L190">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.partition-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.partition-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition(g::AbstractGraph; npartitions::Integer, kwargs...)
partition(g::AbstractGraph, subgraph_vertices)</code></pre><p>Given a graph <code>g</code>, partition <code>g</code> into <code>npartitions</code> partitions or into partitions with <code>nvertices_per_partition</code> vertices per partition. The partitioning tries to keep all subgraphs the same size and minimize edges cut between them.</p><p>Alternatively, specify a desired partitioning with a collection of sugraph vertices.</p><p>Returns a data graph where each vertex contains the corresponding subgraph as vertex data. The edges indicates which subgraphs are connected, and the edge data stores a dictionary with two fields. The field <code>:edges</code> stores a list of the edges of the original graph that were connecting the two subgraphs, and <code>:edge_data</code> stores a dictionary mapping edges of the original graph to the data living on the edges of the original graph, if it existed.</p><p>Therefore, one should be able to extract that data and recreate the original graph from the results of <code>partition</code>.</p><p>A graph partitioning backend such as Metis or KaHyPar needs to be installed for this function to work if the subgraph vertices aren&#39;t specified explicitly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L259-L283">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.partition-Tuple{NDTensors.Algorithm{:mincut_recursive_bisection}, ITensorNetwork, DataGraph}" href="#ITensorNetworks.partition-Tuple{NDTensors.Algorithm{:mincut_recursive_bisection}, ITensorNetwork, DataGraph}"><code>ITensorNetworks.partition</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given an input tn and a rooted binary tree of indices, return a partition of tn with the same binary tree structure as inds<em>btree. Note: in the output partition, we add multiple delta tensors to the network so that   the output graph is guaranteed to be the same binary tree as inds</em>btree. Note: in the output partition, we add multiple scalar tensors. These tensors are used to   make the output partition connected, even if the input <code>tn</code> is disconnected. Note: in the output partition, tensor vertex names will be changed. For a given input   tensor with vertex name <code>v</code><code>, its name in the output partition will be</code>(v, 1)<code>. Any   delta tensor will have name</code>(v, 2)<code>, and any scalar tensor used to maintain the connectivity   of the partition will have name</code>(v, 3)<code>. Note: for a given binary tree with n indices, the output partition will contain 2n-1 vertices,   with each leaf vertex corresponding to a sub tn adjacent to one output index. Keeping these   leaf vertices in the partition makes later</code>approx<em>itensornetwork<code>algorithms more efficient. Note: name of vertices in the output partition are the same as the name of vertices   in</code>inds</em>btree`.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/binary_tree_partition.jl#L45-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.partition_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition_vertices(g::AbstractGraph, subgraph_vertices::Vector)</code></pre><p>Given a graph (<code>g</code>) and groups of vertices defining subgraphs of that graph (<code>subgraph_vertices</code>), return a DataGraph storing the subgraph vertices on the vertices of the graph and with edges denoting which subgraphs of the original graph have edges connecting them, along with edge data storing the original edges that were connecting the subgraphs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L115-L123">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.partition_vertices-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.partition_vertices</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition_vertices(g::AbstractGraph; npartitions, nvertices_per_partition, kwargs...)</code></pre><p>Given a graph <code>g</code>, partition the vertices of <code>g</code> into &#39;npartitions&#39; partitions or into partitions with <code>nvertices_per_partition</code> vertices per partition. Try to keep all subgraphs the same size and minimise edges cut between them Returns a datagraph where each vertex contains the list of vertices involved in that subgraph. The edges state which subgraphs are connected. A graph partitioning backend such as Metis or KaHyPar needs to be installed for this function to work.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L146-L154">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.path_graph_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}" href="#ITensorNetworks.path_graph_structure-Tuple{ITensorNetwork, Vector{&lt;:ITensors.Index}}"><code>ITensorNetworks.path_graph_structure</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given a <code>tn</code> and <code>outinds</code> (a subset of noncommoninds of <code>tn</code>), outputs a maximimally unbalanced directed binary tree DataGraph of <code>outinds</code> defining the desired graph structure</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L11-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.path_graph_structure-Tuple{ITensorNetwork}" href="#ITensorNetworks.path_graph_structure-Tuple{ITensorNetwork}"><code>ITensorNetworks.path_graph_structure</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Outputs a maximimally unbalanced directed binary tree DataGraph defining the desired graph structure</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/mincut.jl#L4-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.randomITensorNetwork-Tuple{Distributions.Distribution, IndsNetwork}" href="#ITensorNetworks.randomITensorNetwork-Tuple{Distributions.Distribution, IndsNetwork}"><code>ITensorNetworks.randomITensorNetwork</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build an ITensor network on a graph specified by the inds network s. Bond<em>dim is given by link</em>space and entries are randomized. The random distribution is based on the input argument <code>distribution</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/specialitensornetworks.jl#L118-L122">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.randomITensorNetwork-Tuple{Type, IndsNetwork}" href="#ITensorNetworks.randomITensorNetwork-Tuple{Type, IndsNetwork}"><code>ITensorNetworks.randomITensorNetwork</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build an ITensor network on a graph specified by the inds network s. Bond<em>dim is given by link</em>space and entries are randomised (normal distribution, mean 0 std 1)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/specialitensornetworks.jl#L95-L97">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.relabel_sites-Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, Dictionaries.AbstractDictionary}" href="#ITensorNetworks.relabel_sites-Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}} where C, Dictionaries.AbstractDictionary}"><code>ITensorNetworks.relabel_sites</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Relabel sites in OpSum according to given site map</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/utility.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.set_partitioning_backend!-Tuple{Union{Missing, String, ITensorNetworks.Backend}}" href="#ITensorNetworks.set_partitioning_backend!-Tuple{Union{Missing, String, ITensorNetworks.Backend}}"><code>ITensorNetworks.set_partitioning_backend!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Set the graph partitioning backend</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L24-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph, Any}" href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph, Any}"><code>ITensorNetworks.subgraphs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">subgraphs(g::AbstractGraph, subgraph_vertices)</code></pre><p>Return a collection of subgraphs of <code>g</code> defined by the subgraph vertices <code>subgraph_vertices</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L206-L211">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph}" href="#ITensorNetworks.subgraphs-Tuple{Graphs.AbstractGraph}"><code>ITensorNetworks.subgraphs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">subgraphs(g::AbstractGraph; npartitions::Integer, kwargs...)</code></pre><p>Given a graph <code>g</code>, partition <code>g</code> into <code>npartitions</code> partitions or into partitions with <code>nvertices_per_partition</code> vertices per partition, returning a list of subgraphs. Try to keep all subgraphs the same size and minimise edges cut between them. A graph partitioning backend such as Metis or KaHyPar needs to be installed for this function to work.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/partition.jl#L216-L224">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.svdTTN-Union{Tuple{VT}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{VT, &lt;:ITensors.Index}, VT}} where {C, VT}" href="#ITensorNetworks.svdTTN-Union{Tuple{VT}, Tuple{C}, Tuple{ITensors.LazyApply.Applied{typeof(sum), Tuple{Array{ITensors.LazyApply.Applied{typeof(*), Tuple{C, ITensors.LazyApply.Prod{ITensors.Ops.Op}}, NamedTuple{(), Tuple{}}}, 1}}, NamedTuple{(), Tuple{}}}, IndsNetwork{VT, &lt;:ITensors.Index}, VT}} where {C, VT}"><code>ITensorNetworks.svdTTN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">svdTTN(os::OpSum{C}, sites::IndsNetwork{V&lt;:Index}, root_vertex::V, kwargs...) where {C,V}</code></pre><p>Construct a dense TreeTensorNetwork from a symbolic OpSum representation of a Hamiltonian, compressing shared interaction channels.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/opsum_to_ttn.jl#L217-L222">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.symmetric_gauge-Tuple{ITensorNetwork}" href="#ITensorNetworks.symmetric_gauge-Tuple{ITensorNetwork}"><code>ITensorNetworks.symmetric_gauge</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Put an ITensorNetwork into the symmetric gauge and also return the message tensors (which are the diagonal bond matrices)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/gauging.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.tdvp-Tuple{Any, Number, ITensorNetworks.AbstractTreeTensorNetwork}" href="#ITensorNetworks.tdvp-Tuple{Any, Number, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensorNetworks.tdvp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tdvp(H::TTN, t::Number, psi0::TTN; kwargs...)</code></pre><p>Use the time dependent variational principle (TDVP) algorithm to approximately compute <code>exp(H*t)*psi0</code> using an efficient algorithm based on alternating optimization of the state tensors and local Krylov exponentiation of H. The time parameter <code>t</code> can be a real or complex number.</p><p>Returns:</p><ul><li><code>psi</code> - time-evolved state</li></ul><p>Optional keyword arguments:</p><ul><li><code>time_step::Number = t</code> - time step to use when evolving the state. Smaller time steps generally give more accurate results but can make the algorithm take more computational time to run.</li><li><code>nsteps::Integer</code> - evolve by the requested total time <code>t</code> by performing <code>nsteps</code> of the TDVP algorithm. More steps can result in more accurate results but require more computational time to run. (Note that only one of the <code>time_step</code> or <code>nsteps</code> parameters can be provided, not both.)</li><li><code>outputlevel::Int = 1</code> - larger outputlevel values resulting in printing more information and 0 means no output</li><li><code>observer</code> - object implementing the <a href="@ref observer">Observer</a> interface which can perform measurements and stop early</li><li><code>write_when_maxdim_exceeds::Int</code> - when the allowed maxdim exceeds this value, begin saving tensors to disk to free memory in large calculations</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/tdvp.jl#L93-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.to_vec-Tuple{Any}" href="#ITensorNetworks.to_vec-Tuple{Any}"><code>ITensorNetworks.to_vec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">to_vec(x)</code></pre><p>Transform <code>x</code> into a <code>Vector</code>. Returns the vector and a closure which inverts the transformation.</p><p>Modeled after <code>FiniteDifferences.to_vec</code>:</p><p>https://github.com/JuliaDiff/FiniteDifferences.jl/blob/main/src/to_vec.jl</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/solver_utils.jl#L4-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensorNetworks.update_message_tensor-Tuple{ITensorNetwork, Vector, Vector{ITensorNetwork}}" href="#ITensorNetworks.update_message_tensor-Tuple{ITensorNetwork, Vector, Vector{ITensorNetwork}}"><code>ITensorNetworks.update_message_tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><p>DO a single update of a message tensor using the current subgraph and the incoming mts</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/beliefpropagation.jl#L30-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensors.apply-Tuple{ITensorNetworks.AbstractTreeTensorNetwork, ITensorNetworks.AbstractTreeTensorNetwork}" href="#ITensors.apply-Tuple{ITensorNetworks.AbstractTreeTensorNetwork, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensors.apply</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Overload of <code>ITensors.apply</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/contract.jl#L58-L60">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensors.dmrg-Tuple{Any, ITensorNetworks.AbstractTreeTensorNetwork}" href="#ITensors.dmrg-Tuple{Any, ITensorNetworks.AbstractTreeTensorNetwork}"><code>ITensors.dmrg</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Overload of <code>ITensors.dmrg</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/dmrg.jl#L19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ITensors.replaceinds-Tuple{ITensors.ITensor, Dict{&lt;:ITensors.Index, &lt;:ITensors.Index}}" href="#ITensors.replaceinds-Tuple{ITensors.ITensor, Dict{&lt;:ITensors.Index, &lt;:ITensors.Index}}"><code>ITensors.replaceinds</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Given an input tensor and a Dict (ind<em>to</em>newind), replace inds of tensor that are also keys of ind<em>to</em>newind to the value of ind<em>to</em>newind. Note that it is the same as ITensors.replaceinds(tensor, collect(keys(ind<em>to</em>newind)) =&gt; collect(values(ind<em>to</em>newind))). Based on benchmark, this implementation is more efficient when the size of ind<em>to</em>newind is large. TODO: we can remove this function once the original replaceinds performance is improved.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/itensors.jl#L45-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KrylovKit.eigsolve-Tuple{Any, ITensorNetworks.AbstractTreeTensorNetwork}" href="#KrylovKit.eigsolve-Tuple{Any, ITensorNetworks.AbstractTreeTensorNetwork}"><code>KrylovKit.eigsolve</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Overload of <code>KrylovKit.eigsolve</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/dmrg.jl#L28-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KrylovKit.linsolve" href="#KrylovKit.linsolve"><code>KrylovKit.linsolve</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">linsolve(
    A::ITensorNetworks.AbstractTreeTensorNetwork,
    b::ITensorNetworks.AbstractTreeTensorNetwork,
    x₀::ITensorNetworks.AbstractTreeTensorNetwork
)
linsolve(
    A::ITensorNetworks.AbstractTreeTensorNetwork,
    b::ITensorNetworks.AbstractTreeTensorNetwork,
    x₀::ITensorNetworks.AbstractTreeTensorNetwork,
    a₀::Number
)
linsolve(
    A::ITensorNetworks.AbstractTreeTensorNetwork,
    b::ITensorNetworks.AbstractTreeTensorNetwork,
    x₀::ITensorNetworks.AbstractTreeTensorNetwork,
    a₀::Number,
    a₁::Number;
    kwargs...
)
</code></pre><p>Compute a solution x to the linear system:</p><p>(a₀ + a₁ * A)*x = b</p><p>using starting guess x₀. Leaving a₀, a₁ set to their default values solves the  system A*x = b.</p><p>To adjust the balance between accuracy of solution and speed of the algorithm, it is recommed to first try adjusting the <code>solver_tol</code> keyword argument descibed below.</p><p>Keyword arguments:</p><ul><li><code>ishermitian::Bool=false</code> - should set to true if the MPO A is Hermitian</li><li><code>solver_krylovdim::Int=30</code> - max number of Krylov vectors to build on each solver iteration</li><li><code>solver_maxiter::Int=100</code> - max number outer iterations (restarts) to do in the solver step</li><li><code>solver_tol::Float64=1E-14</code> - tolerance or error goal of the solver</li></ul><p>Overload of <code>KrylovKit.linsolve</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/linsolve.jl#L2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NDTensors.contract-Tuple{ITensorNetworks.AbstractTreeTensorNetwork, ITensorNetworks.AbstractTreeTensorNetwork}" href="#NDTensors.contract-Tuple{ITensorNetworks.AbstractTreeTensorNetwork, ITensorNetworks.AbstractTreeTensorNetwork}"><code>NDTensors.contract</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Overload of <code>ITensors.contract</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/treetensornetworks/solvers/contract.jl#L51-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Observers.update!-Tuple{Nothing}" href="#Observers.update!-Tuple{Nothing}"><code>Observers.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Overload of <code>Observers.update!</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mtfishman/ITensorNetworks.jl/blob/472ceb6c3e1dcc2d41e5fa0729b0774fb43d15d1/src/observers.jl#L1-L3">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 22 May 2023 18:57">Monday 22 May 2023</span>. Using Julia version 1.9.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
