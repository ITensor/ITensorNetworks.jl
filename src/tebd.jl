function tebd(â„‹::Sum, Ïˆ::AbstractITensorNetwork; Î², Î”Î², maxdim, cutoff, print_frequency=10, ortho=false)
  ğ’° = exp(-Î”Î² * â„‹; alg=Trotter{2}())
  # Imaginary time evolution terms
  s = siteinds(Ïˆ)
  uâƒ— = Vector{ITensor}(ğ’°, s)
  nsteps = Int(Î² Ã· Î”Î²)
  for step in 1:nsteps
    if step % print_frequency == 0
      @show step, (step - 1) * Î”Î², Î²
    end
    Ïˆ = insert_links(Ïˆ)
    Ïˆ = apply(uâƒ—, Ïˆ; cutoff, maxdim, normalize=true, ortho)
    if ortho
      for v in vertices(Ïˆ)
        Ïˆ = orthogonalize(Ïˆ, v)
      end
    end
  end
  return Ïˆ
end

# using ITensors
# using ITensorNetworks
# using Dictionaries
# using NamedGraphs
# using SplitApplyCombine
# using ITensors.ContractionSequenceOptimization
# 
# using Graphs: AbstractEdge, AbstractGraph, Graph, add_edge!

# to_tuple(x) = (x,)
# to_tuple(x::Tuple) = x

# function group_terms(â„‹::Sum, g)
#   grouped_terms = group(ITensors.terms(â„‹)) do t
#     findfirst(edges(g)) do e
#       to_tuple.(ITensors.sites(t)) âŠ† [src(e), dst(e)]
#     end
#   end
#   return Sum(collect(sum.(grouped_terms)))
# end

# function cartesian_to_linear(dims::Tuple)
#   return Dictionary(vec(Tuple.(CartesianIndices(dims))), 1:prod(dims))
# end

# NamedGraphs.NamedDimGraph(vertices::Vector) = NamedDimGraph(tuple.(vertices))
# NamedGraphs.NamedDimGraph(vertices::Vector{<:Tuple}) = NamedDimGraph(Graph(length(vertices)); vertices)
# 
# function rename_vertices(e::AbstractEdge, name_map::Dictionary)
#   return typeof(e)(name_map[src(e)], name_map[dst(e)])
# end
# 
# function rename_vertices(g::NamedDimGraph, name_map::Dictionary)
#   original_vertices = vertices(g)
#   new_vertices = getindices(name_map, original_vertices)
#   new_g = NamedDimGraph(new_vertices)
#   for e in edges(g)
#     add_edge!(new_g, rename_vertices(e, name_map))
#   end
#   return new_g
# end
# 
# function rename_vertices(g::NamedDimGraph, name_map::Function)
#   original_vertices = vertices(g)
#   return rename_vertices(g, Dictionary(original_vertices, name_map.(original_vertices)))
# end

# # Convert to real if possible
# maybe_real(x::Real) = x
# maybe_real(x::Complex) = iszero(imag(x)) ? real(x) : x

# function ITensors.ITensor(o::Op, s::IndsNetwork)
#   sâƒ— = [only(s[náµ¢]) for náµ¢ in Ops.sites(o)]
#   return op(Ops.which_op(o), sâƒ—; Ops.params(o)...)
# end
# 
# function ITensors.ITensor(âˆo::Prod, s::IndsNetwork)
#   T = ITensor(1.0)
#   for oáµ¢ in Ops.terms(âˆo)
#     Táµ¢ = ITensor(oáµ¢, s)
#     # For now, only support operators on distinct
#     # sites.
#     @assert !hascommoninds(T, Táµ¢)
#     T *= Táµ¢
#   end
#   return T
# end

# # Tensor sum: `A âŠ B = A âŠ— Iá´® + Iá´¬ âŠ— B`
# # https://github.com/JuliaLang/julia/issues/13333#issuecomment-143825995
# # "PRESERVATION OF TENSOR SUM AND TENSOR PRODUCT"
# # C. S. KUBRUSLY and N. LEVAN
# # https://www.emis.de/journals/AMUC/_vol-80/_no_1/_kubrusly/kubrusly.pdf
# function tensor_sum(A::ITensor, B::ITensor)
#   extend_A = filterinds(uniqueinds(B, A); plev=0)
#   extend_B = filterinds(uniqueinds(A, B); plev=0)
#   for i in extend_A
#     A *= op("I", i)
#   end
#   for i in extend_B
#     B *= op("I", i)
#   end
#   return A + B
# end

# function ITensors.ITensor(âˆ‘o::Sum, s::IndsNetwork)
#   T = ITensor(0)
#   for oáµ¢ in Ops.terms(âˆ‘o)
#     Táµ¢ = ITensor(oáµ¢, s)
#     T = tensor_sum(T, Táµ¢)
#   end
#   return T
# end
# 
# function ITensors.ITensor(o::Scaled, s::IndsNetwork)
#   return maybe_real(Ops.coefficient(o)) * ITensor(Ops.argument(o), s)
# end
# 
# function ITensors.ITensor(o::Ops.Exp, s::IndsNetwork)
#   return exp(ITensor(Ops.argument(o), s))
# end
# 
# function Base.Vector{ITensor}(o::Union{Sum,Prod}, s::IndsNetwork)
#   Tâƒ— = ITensor[]
#   for oáµ¢ in Ops.terms(o)
#     Táµ¢ = ITensor(oáµ¢, s)
#     Tâƒ— = [Tâƒ—; Táµ¢]
#   end
#   return Tâƒ—
# end

# using ITensorNetworks: âŠ”

# function neighbor_vertices(Ïˆ::ITensorNetwork, T::ITensor)
#   ÏˆT = Ïˆ âŠ” ITensorNetwork([T])
#   vâƒ— = neighbors(ÏˆT, (2, 1))
#   return Base.tail.(vâƒ—)
# end

# function ITensors.orthogonalize(Ïˆ::ITensorNetwork, source_vertex::Tuple)
#   spanning_tree_edges = post_order_dfs_edges(bfs_tree(Ïˆ, source_vertex), source_vertex)
#   for e in spanning_tree_edges
#     Ïˆ = orthogonalize(Ïˆ, e)
#   end
#   return Ïˆ
# end

# function ITensors.apply(o::ITensor, Ïˆ::ITensorNetwork; cutoff, maxdim, normalize=false, ortho=false)
#   Ïˆ = copy(Ïˆ)
#   vâƒ— = neighbor_vertices(Ïˆ, o)
#   if length(vâƒ—) == 1
#     if ortho
#       Ïˆ = orthogonalize(Ïˆ, vâƒ—[1])
#     end
#     oÏˆáµ¥ = apply(o, Ïˆ[vâƒ—[1]])
#     if normalize
#       oÏˆáµ¥ ./= norm(oÏˆáµ¥)
#     end
#     Ïˆ[vâƒ—[1]] = oÏˆáµ¥
#   elseif length(vâƒ—) == 2
#     e = vâƒ—[1] => vâƒ—[2]
#     if !has_edge(Ïˆ, e)
#       error("Vertices where the gates are being applied must be neighbors for now.")
#     end
#     if ortho
#       Ïˆ = orthogonalize(Ïˆ, vâƒ—[1])
#     end
#     oÏˆáµ¥ = apply(o, Ïˆ[vâƒ—[1]] * Ïˆ[vâƒ—[2]])
#     Ïˆáµ¥â‚, Ïˆáµ¥â‚‚ = factorize(oÏˆáµ¥, inds(Ïˆ[vâƒ—[1]]); cutoff, maxdim, tags=ITensorNetworks.edge_tag(e))
#     if normalize
#       Ïˆáµ¥â‚ ./= norm(Ïˆáµ¥â‚)
#       Ïˆáµ¥â‚‚ ./= norm(Ïˆáµ¥â‚‚)
#     end
#     Ïˆ[vâƒ—[1]] = Ïˆáµ¥â‚
#     Ïˆ[vâƒ—[2]] = Ïˆáµ¥â‚‚
#   elseif length(vâƒ—) < 1
#     error("Gate being applied does not share indices with tensor network.")
#   elseif length(vâƒ—) > 2
#     error("Gates with more than 2 sites is not supported yet.")
#   end
#   return Ïˆ
# end

# function ITensors.apply(oâƒ—::Vector{ITensor}, Ïˆ::ITensorNetwork; cutoff, maxdim, normalize=false, ortho=false)
#   oâƒ—Ïˆ = Ïˆ
#   for oáµ¢ in oâƒ—
#     oâƒ—Ïˆ = apply(oáµ¢, oâƒ—Ïˆ; cutoff, maxdim, normalize, ortho)
#   end
#   return oâƒ—Ïˆ
# end
# 
# function ITensors.apply(oâƒ—::Scaled, Ïˆ::ITensorNetwork; cutoff, maxdim, normalize=false, ortho=false)
#   return maybe_real(Ops.coefficient(oâƒ—)) * apply(Ops.argument(oâƒ—), Ïˆ; cutoff, maxdim, normalize, ortho)
# end

# function Base.:*(c::Number, Ïˆ::ITensorNetwork)
#   vâ‚ = first(vertices(Ïˆ))
#   cÏˆ = copy(Ïˆ)
#   cÏˆ[vâ‚] *= c
#   return cÏˆ
# end

# function ITensors.apply(oâƒ—::Prod, Ïˆ::ITensorNetwork; cutoff, maxdim, normalize=false, ortho=false)
#   oâƒ—Ïˆ = Ïˆ
#   for oáµ¢ in oâƒ—
#     oâƒ—Ïˆ = apply(oáµ¢, oâƒ—Ïˆ; cutoff, maxdim, normalize, ortho)
#   end
#   return oâƒ—Ïˆ
# end
# 
# function ITensors.apply(o::Op, Ïˆ::ITensorNetwork; cutoff, maxdim, normalize=false, ortho=false)
#   return apply(ITensor(o, siteinds(Ïˆ)), Ïˆ; cutoff, maxdim, normalize, ortho)
# end

# function flattened_inner_network(Ï•::ITensorNetwork, Ïˆ::ITensorNetwork)
#   tn = inner(prime(Ï•; sites=[]), Ïˆ)
#   for v in vertices(Ïˆ)
#     tn = ITensors.contract(tn, (2, v...) => (1, v...))
#   end
#   return tn
# end
# 
# function contract_inner(Ï•::ITensorNetwork, Ïˆ::ITensorNetwork; sequence=nothing)
#   tn = inner(prime(Ï•; sites=[]), Ïˆ)
#   # TODO: convert to an IndsNetwork and compute the contraction sequence
#   for v in vertices(Ïˆ)
#     tn = ITensors.contract(tn, (2, v...) => (1, v...))
#   end
#   if isnothing(sequence)
#     sequence = optimal_contraction_sequence(tn)
#   end
#   return ITensors.contract(tn; sequence)[]
# end

# norm2(Ïˆ::ITensorNetwork; sequence) = contract_inner(Ïˆ, Ïˆ; sequence)

# function ITensors.expect(op::String, Ïˆ::ITensorNetwork; cutoff=nothing, maxdim=nothing, ortho=false, sequence=nothing)
#   res = Dictionary(vertices(Ïˆ), Vector{Float64}(undef, nv(Ïˆ)))
#   if isnothing(sequence)
#     sequence = optimal_contraction_sequence(flattened_inner_network(Ïˆ, Ïˆ))
#   end
#   normÏˆÂ² = norm2(Ïˆ; sequence)
#   for v in vertices(Ïˆ)
#     O = ITensor(Op(op, v), s)
#     OÏˆ = apply(O, Ïˆ; cutoff, maxdim, ortho)
#     res[v] = contract_inner(Ïˆ, OÏˆ; sequence) / normÏˆÂ²
#   end
#   return res
# end
# 
# function ITensors.expect(â„‹::OpSum, Ïˆ::ITensorNetwork; cutoff=nothing, maxdim=nothing, ortho=false, sequence=nothing)
#   s = siteinds(Ïˆ)
#   # hâƒ— = Vector{ITensor}(â„‹, s)
#   if isnothing(sequence)
#     sequence = optimal_contraction_sequence(flattened_inner_network(Ïˆ, Ïˆ))
#   end
#   hâƒ—Ïˆ = [apply(háµ¢, Ïˆ; cutoff, maxdim, ortho) for háµ¢ in ITensors.terms(â„‹)]
#   Ïˆháµ¢Ïˆ = [contract_inner(Ïˆ, háµ¢Ïˆ; sequence) for háµ¢Ïˆ in hâƒ—Ïˆ]
#   Ïˆhâƒ—Ïˆ = sum(Ïˆháµ¢Ïˆ)
#   ÏˆÏˆ = norm2(Ïˆ; sequence)
#   return Ïˆhâƒ—Ïˆ / ÏˆÏˆ
# end

# function ITensors.expect(opsum_sum::Sum{<:OpSum}, Ïˆ::ITensorNetwork; cutoff=nothing, maxdim=nothing, ortho=true, sequence=nothing)
#   return expect(sum(Ops.terms(opsum_sum)), Ïˆ; cutoff, maxdim, ortho, sequence)
# end

# function randomITensorNetwork(s; link_space)
#   Ïˆ = ITensorNetwork(s; link_space)
#   for v in vertices(Ïˆ)
#     Ïˆáµ¥ = copy(Ïˆ[v])
#     randn!(Ïˆáµ¥)
#     Ïˆáµ¥ ./= norm(Ïˆáµ¥)
#     Ïˆ[v] = Ïˆáµ¥
#   end
#   return Ïˆ
# end

# function ITensors.MPO(opsum::OpSum, s::IndsNetwork)
#   s_linear = [only(s[v]) for v in 1:nv(s)]
#   return MPO(opsum, s_linear)
# end
# 
# function ITensors.MPO(opsum_sum::Sum{<:OpSum}, s::IndsNetwork)
#   return MPO(sum(Ops.terms(opsum_sum)), s)
# end

# function ITensors.randomMPS(s::IndsNetwork, args...; kwargs...)
#   s_linear = [only(s[v]) for v in 1:nv(s)]
#   return randomMPS(s_linear, args...; kwargs...)
# end
# 
# function ITensors.MPS(s::IndsNetwork, args...; kwargs...)
#   s_linear = [only(s[v]) for v in 1:nv(s)]
#   return MPS(s_linear, args...; kwargs...)
# end

# maybe_only(x) = x
# maybe_only(x::Tuple{T}) where {T} = only(x)

# function ising(g::AbstractGraph; h)
#   â„‹ = OpSum()
#   for e in edges(g)
#     â„‹ -= "Z", maybe_only(src(e)), "Z", maybe_only(dst(e))
#   end
#   for v in vertices(g)
#     â„‹ += h, "X", maybe_only(v)
#   end
#   return â„‹
# end

